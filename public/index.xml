<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Wei Haoyu</title>
    <link>http://localhost:1313/</link>
    <description>Recent content on Wei Haoyu</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 27 Jul 2025 21:06:51 +0800</lastBuildDate>
    <atom:link href="http://localhost:1313/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Welcome!</title>
      <link>http://localhost:1313/posts/hello-world/</link>
      <pubDate>Sun, 27 Jul 2025 21:06:51 +0800</pubDate>
      <guid>http://localhost:1313/posts/hello-world/</guid>
      <description>&lt;p&gt;I am Haoyu Wei. My passion lies in the architecture of search, ads, and recommender systems, with a sharp focus on refactoring, performance tuning, Retrieval-Augmented Generation (RAG), and CUDA kernel development.&lt;/p&gt;&#xA;&lt;p&gt;If my profile resonates with you, feel free to reach me at +86 134 6570 0709. My core belief: learn by doing.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Background </title>
      <link>http://localhost:1313/posts/why/</link>
      <pubDate>Sun, 27 Jul 2025 21:05:54 +0800</pubDate>
      <guid>http://localhost:1313/posts/why/</guid>
      <description>&lt;h2 id=&#34;work-history&#34;&gt;Work History&lt;/h2&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;-bytedance&#34;&gt;• ByteDance&lt;/h3&gt;&#xA;&lt;p&gt;Shanghai | Oct 2024 – Mar 2025&#xA;&lt;!-- raw HTML omitted --&gt;&#xA;Recommendation Architecture Engineer&lt;/p&gt;&#xA;&lt;p&gt;Ranking performance optimization &amp;amp; business support&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;-tencent&#34;&gt;• Tencent&lt;/h3&gt;&#xA;&lt;p&gt;Shenzhen | Mar 2025 – Jun 2025&#xA;&lt;!-- raw HTML omitted --&gt;&#xA;Advertising Engine Engineer&lt;/p&gt;&#xA;&lt;p&gt;End-to-end RPC refactor/migration &amp;amp; DAG mechanism development&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;-microsoft&#34;&gt;• Microsoft&lt;/h3&gt;&#xA;&lt;p&gt;Suzhou | Jun 2025 – Present&#xA;&lt;!-- raw HTML omitted --&gt;&#xA;Bing Search Engineer&lt;/p&gt;&#xA;&lt;p&gt;OPE (Outstanding-Personal-Entrepreneur)&lt;/p&gt;&#xA;&lt;h2 id=&#34;educaion&#34;&gt;Educaion&lt;/h2&gt;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;• Shanghai Jiao Tong University&#xA;M.S. in Computer Science | Sep 2023 – Mar 2026 (expected)&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;• Hefei University of Technology&#xA;B.Eng. in Communication Engineering | Sep 2019 – Jun 2023&lt;/p&gt;&#xA;&lt;h2 id=&#34;publication&#34;&gt;Publication&lt;/h2&gt;&#xA;&lt;p&gt;• Haoyu Wei, Jingyu Ke, Ruibang Liu, and Guoqiang Li. &lt;a href=&#34;https://eprint.iacr.org/2025/1152&#34;&gt;ZK-ProVer: Proving Programming Verification in Non-Interactive Zero-Knowledge Proofs.&lt;/a&gt; In Proceedings of the 27th International Conference on Formal Engineering Methods (ICFEM&#39;25)&lt;/p&gt;&#xA;&lt;h2 id=&#34;competitions--honors&#34;&gt;Competitions &amp;amp; Honors&lt;/h2&gt;&#xA;&lt;p&gt;• 3rd Place, OceanBase Vector Database Development Challenge – Shanghai&lt;/p&gt;&#xA;&lt;p&gt;• Elite Talent, Tencent Rhino-Bird Open-Source Program&lt;/p&gt;&#xA;&lt;p&gt;• 1st Place, Alibaba Cloud Tianchi Development Competition&lt;/p&gt;</description>
    </item>
    <item>
      <title></title>
      <link>http://localhost:1313/posts/3ts/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/3ts/</guid>
      <description>&lt;p&gt;点击返回&lt;a href=&#34;https://2549141519.github.io/#/toc&#34;&gt;🔗我的博客文章目录&lt;/a&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;目录&#xA;{:toc}&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;!-- raw HTML omitted --&gt;&#xA;&lt;h1 id=&#34;3ts&#34;&gt;3TS&lt;/h1&gt;&#xA;&lt;p&gt;&lt;img src=&#34;../blogImg/1.png&#34; alt=&#34;Alt text&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;数据库中执行一致性测试&#34;&gt;数据库中执行一致性测试&lt;/h1&gt;&#xA;&lt;h1 id=&#34;1-postgresql安装&#34;&gt;1. PostgreSQL安装&lt;/h1&gt;&#xA;&lt;h2 id=&#34;11-下载-postgresql-15-的源码&#34;&gt;1.1 下载 PostgreSQL 15 的源码&lt;/h2&gt;&#xA;&lt;p&gt;&lt;img src=&#34;../blogImg/2.png&#34; alt=&#34;Alt text&#34;&gt;&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;wget https://ftp.postgresql.org/pub/source/v15.0/postgresql-15.0.tar.gz&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;12-解压源码包&#34;&gt;1.2 解压源码包&lt;/h2&gt;&#xA;&lt;p&gt;解压下载的源码包：&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;tar -xzvf postgresql-15.0.tar.gz&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;13-编译并安装-postgresql&#34;&gt;1.3 编译并安装 PostgreSQL&lt;/h2&gt;&#xA;&lt;p&gt;进入源码目录，执行以下命令进行编译和安装：&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;bash&#xA;cd postgresql-15.0&#xA;./configure&#xA;make&#xA;sudo make install&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;14-创建数据库用户和数据目录&#34;&gt;1.4 创建数据库用户和数据目录&lt;/h2&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;sudo mkdir /usr/local/pgsql&#xA;sudo mkdir /usr/local/pgsql/data&#xA;sudo chown nlove /usr/local/pgsql/data&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;15-初始化数据库&#34;&gt;1.5 初始化数据库&lt;/h2&gt;&#xA;&lt;p&gt;初始化数据库:&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;/usr/local/pgsql/bin/initdb -D /usr/local/pgsql/data&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&#34;../blogImg/3.png&#34; alt=&#34;Alt text&#34;&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;16-启动-postgresql-服务&#34;&gt;1.6 启动 PostgreSQL 服务&lt;/h2&gt;&#xA;&lt;p&gt;启动 PostgreSQL 数据库服务：&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;/usr/local/pgsql/bin/pg_ctl -D /usr/local/pgsql/data -l logfile start&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&#34;../blogImg/4.png&#34; alt=&#34;Alt text&#34;&gt;&lt;br&gt;&#xA;创建数据库 test：&lt;/p&gt;</description>
    </item>
    <item>
      <title></title>
      <link>http://localhost:1313/posts/bigtable-%E7%BB%93%E6%9E%84%E5%8C%96%E6%95%B0%E6%8D%AE%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8%E7%B3%BB%E7%BB%9F/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/bigtable-%E7%BB%93%E6%9E%84%E5%8C%96%E6%95%B0%E6%8D%AE%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8%E7%B3%BB%E7%BB%9F/</guid>
      <description>&lt;p&gt;点击返回&lt;a href=&#34;https://2549141519.github.io/#/toc&#34;&gt;🔗我的博客文章目录&lt;/a&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;目录&#xA;{:toc}&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;!-- raw HTML omitted --&gt;&#xA;&lt;p&gt;paper &lt;a href=&#34;https://storage.googleapis.com/gweb-research2023-media/pubtools/4443.pdf&#34;&gt;link&lt;/a&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;1-bigtable介绍&#34;&gt;1. Bigtable介绍&lt;/h1&gt;&#xA;&lt;p&gt;Google的 Bigtable 是一种分布式存储系统，专门用于管理结构化数据，具有高度的可扩展性。&lt;br&gt;&#xA;在许多方面，Bigtable类似于数据库:它与数据库共享许多实现策略。bigtables不支持完整的关系数据模型，相反，它为客户端提供了一个简单的数据模型，该模型支持对数据布局和格式的动态控制，并允许客户端推断底层存储中表示的数据的局部属性。使用可以是任意字符串的行名和列名对数据进行索引。Bigtable模式参数允许客户端动态控制从内存中还是从磁盘中提供数据。&lt;/p&gt;&#xA;&lt;h1 id=&#34;2-数据模型&#34;&gt;2. 数据模型&lt;/h1&gt;&#xA;&lt;p&gt;Bigtable是一个稀疏的、分布式的、持久的多维排序映射。映射由行键、列键和时间戳索引，映射中的每个值都是一个未解释的字节数组。&lt;/p&gt;&#xA;&lt;p&gt;稀疏的：Bigtable 表格是稀疏的，意味着在表格中不需要为每个行和列都填充数据。只在需要的位置存储数据，这样可以节省存储空间。空白的单元格不会占用资源。&lt;br&gt;&#xA;分布式的：Bigtable 是分布式的，它可以将数据存储在成千上万台服务器上，每个表格会被分割成多个“tablet”（子表），并分布在不同的服务器上。&lt;br&gt;&#xA;持久的：Bigtable 保证数据持久化，即数据被存储后不会丢失，甚至在服务器故障或重启的情况下，数据依然是安全的。这通过底层的 Google 文件系统（GFS）来实现。&lt;br&gt;&#xA;多维排序映射：Bigtable 将数据组织为一个多维的结构，其中数据通过行键、列键和时间戳来定位。这类似于一个三维的哈希表，不同的键为不同维度的数据提供索引。&lt;br&gt;&#xA;行键：行键是表中每一行的唯一标识符。行键按字典序排列，使得 Bigtable 能高效地执行按行范围查询。&lt;br&gt;&#xA;列键：列键用于标识每一行中不同的列数据，列按列族（column family）组织，使得列键具有分组的灵活性。&lt;br&gt;&#xA;时间戳：Bigtable 中的每个单元格（即某一行键和列键交叉的地方）可以存储同一数据的多个版本，每个版本都有一个时间戳。通过时间戳，Bigtable 可以存储历史版本的数据，支持按时间查询。&lt;br&gt;&#xA;未解释的字节数组：映射中的每个值实际上是一个字节数组。Bigtable 不关心这些字节的具体内容，它不提供对数据类型的解释，数据的解析留给应用程序处理。&lt;br&gt;&#xA;三维索引（行键、列键、时间戳）访问数据：&lt;br&gt;&#xA;&lt;code&gt;(row:string, column:string, time:int64) → string&lt;/code&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;21-行键&#34;&gt;2.1 行键&lt;/h2&gt;&#xA;&lt;p&gt;Bigtable的行键是任意字符串。对单行键下数据的每次读取或写入都是原子的。&lt;br&gt;&#xA;按字典顺序维护数据：&lt;br&gt;&#xA;Bigtable 使用 rowkey 来对数据进行排序，并按照字典顺序进行存储。这样，数据行在存储时是按行键（rowkey）的字典序排列的。&lt;br&gt;&#xA;行范围动态分区：&lt;br&gt;&#xA;Bigtable 会动态将表格中的行划分为多个连续的范围，每个范围称为一个“tablet”。这些 tablet 是系统在集群中的分配和负载平衡的最小单位。随着数据的增加或访问负载的变化，系统可以自动调整 tablet 的大小和位置。&lt;br&gt;&#xA;短范围读取的有效性：&lt;br&gt;&#xA;因为数据是按行键的字典顺序存储的，所以当我们查询特定范围的数据时，系统只需要从相关的几个 tablet 中读取数据。这意味着短范围读取（例如按范围查询相邻的行）通常只需要与少量的机器通信。&lt;br&gt;&#xA;利用行键来优化数据访问的局部性：&lt;br&gt;&#xA;客户端可以根据应用的需求来选择合适的行键，以便将相关的数据存储在连续的位置上，这样可以提高数据访问的局部性。例如，在一个 Webtable 中，可以通过倒置 URL 的主机名（如将 &lt;code&gt;maps.google.com&lt;/code&gt; 变为 &lt;code&gt;com.google.maps&lt;/code&gt;）来确保同一个域名下的页面（如 &lt;code&gt;maps.google.com/index.html&lt;/code&gt;）被存储在相邻的行中。&lt;/p&gt;</description>
    </item>
    <item>
      <title></title>
      <link>http://localhost:1313/posts/bison%E8%AF%AD%E6%B3%95%E5%88%86%E6%9E%90/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/bison%E8%AF%AD%E6%B3%95%E5%88%86%E6%9E%90/</guid>
      <description>&lt;p&gt;点击返回&lt;a href=&#34;https://2549141519.github.io/#/toc&#34;&gt;🔗我的博客文章目录&lt;/a&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;目录&#xA;{:toc}&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;!-- raw HTML omitted --&gt;&#xA;&lt;h1 id=&#34;1-bison简介&#34;&gt;1. Bison简介&lt;/h1&gt;&#xA;&lt;p&gt;Bison是yacc的现代版本，由自由软件基金会的GNU项目帮助发布。&lt;br&gt;&#xA;Bison分为&lt;a href=&#34;https://www.gnu.org/software/bison/&#34;&gt;Linux版本&lt;/a&gt;和&lt;a href=&#34;https://gnuwin32.sourceforge.net/projects/bison.htm/&#34;&gt;Windows版本&lt;/a&gt;。&lt;/p&gt;&#xA;&lt;h1 id=&#34;2-bison工作原理&#34;&gt;2. Bison工作原理&lt;/h1&gt;&#xA;&lt;h2 id=&#34;21-bison和flex协同工作&#34;&gt;2.1 Bison和Flex协同工作&lt;/h2&gt;&#xA;&lt;p&gt;&lt;a href=&#34;Flex%E8%AF%8D%E6%B3%95%E5%88%86%E6%9E%90.md&#34;&gt;Flex&lt;/a&gt;：词法分析器，将输入分割成一个个有意义的词块，称为记号（token）&lt;br&gt;&#xA;Bison：语法分析器，根据给定的语法规则将Flex生成的tokens转换为抽象语法树（AST）&lt;br&gt;&#xA;编译顺序：&lt;br&gt;&#xA;&lt;img src=&#34;../blogImg/Bison1.PNG&#34; alt=&#34;图片1&#34;&gt;&lt;br&gt;&#xA;协同工作顺序：&lt;br&gt;&#xA;&lt;img src=&#34;../blogImg/Bison2.PNG&#34; alt=&#34;图片2&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;3-bison的输入&#34;&gt;3. Bison的输入&lt;/h1&gt;&#xA;&lt;p&gt;Bison的输入为&lt;code&gt;*.y&lt;/code&gt;文件：&lt;/p&gt;&#xA;&lt;h2 id=&#34;31定义段&#34;&gt;3.1定义段&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;以c语法写的一些定义和声明，该部分以符号&lt;code&gt;%{&lt;/code&gt;和&lt;code&gt;%}&lt;/code&gt;包裹。&lt;/li&gt;&#xA;&lt;li&gt;对词法的终结符和非终结符的声明，主要包含：&lt;code&gt;%token&lt;/code&gt;,&lt;code&gt;%left&lt;/code&gt;,&lt;code&gt;%right&lt;/code&gt;,&lt;code&gt;%nonassoc&lt;/code&gt;,&lt;code&gt;%union&lt;/code&gt;,&lt;code&gt;%type&lt;/code&gt;,&lt;code&gt;%start&lt;/code&gt;。&lt;br&gt;&#xA;&lt;code&gt;%token&lt;/code&gt;定义语法中使用的终结符。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;&lt;code&gt;%left&lt;/code&gt;,&lt;code&gt;%right&lt;/code&gt;,&lt;code&gt;%nonassoc&lt;/code&gt;也是定义词法中的终结符，但它们定义的终结符具有某种优先级和结合性。&lt;br&gt;&#xA;&lt;code&gt;%left&lt;/code&gt;表示左结合，&lt;code&gt;%right&lt;/code&gt;表示右结合，&lt;code&gt;%nonassoc&lt;/code&gt;表示不可结合。&lt;/p&gt;&#xA;&lt;p&gt;&lt;code&gt;%union&lt;/code&gt;为c语言的联合类型，声明语法分析器中符号值的类型。&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;%union {&#xA;    int num;&#xA;    char *str;&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;一旦联合类型被定义，就需要告诉Bison每种符号使用的值类型，通过在尖括号&lt;code&gt;&amp;lt;&amp;gt;&lt;/code&gt;中的联合类型的相应成员名来确定。&lt;br&gt;&#xA;&lt;code&gt;%token &amp;lt;num&amp;gt; TOKEN1&lt;/code&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;code&gt;%type&lt;/code&gt;定义语法中使用的非终结符。&lt;/p&gt;&#xA;&lt;p&gt;&lt;code&gt;%start&lt;/code&gt;定义语法分析的开始符号，开始符号必须具备一个空规则，为了让开始输入的记号能从起始符号开始匹配。&lt;/p&gt;&#xA;&lt;h2 id=&#34;32-语法规则段&#34;&gt;3.2 语法规则段&lt;/h2&gt;&#xA;&lt;p&gt;&lt;img src=&#34;../blogImg/Bison3.PNG&#34; alt=&#34;图片3&#34;&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;33-辅助函数段&#34;&gt;3.3 辅助函数段&lt;/h2&gt;&#xA;&lt;p&gt;&lt;img src=&#34;../blogImg/Bison4.PNG&#34; alt=&#34;图片4&#34;&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title></title>
      <link>http://localhost:1313/posts/flex%E8%AF%8D%E6%B3%95%E5%88%86%E6%9E%90/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/flex%E8%AF%8D%E6%B3%95%E5%88%86%E6%9E%90/</guid>
      <description>&lt;p&gt;点击返回&lt;a href=&#34;https://2549141519.github.io/#/toc&#34;&gt;🔗我的博客文章目录&lt;/a&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;目录&#xA;{:toc}&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;!-- raw HTML omitted --&gt;&#xA;&lt;h1 id=&#34;1-flex的使用&#34;&gt;1. Flex的使用&lt;/h1&gt;&#xA;&lt;p&gt;.l是Flex源文件，经过Flex编译器，默认生成lex.yy.c文件。&lt;br&gt;&#xA;c编译器默认生成名为a.out的可执行文件。&lt;br&gt;&#xA;输入流经过a.out文件，输出词法单元序列。&lt;br&gt;&#xA;&lt;img src=&#34;../blogImg/Flex1.PNG&#34; alt=&#34;图片1&#34;&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;11-flex源程序的一般形式&#34;&gt;1.1 Flex源程序的一般形式&lt;/h2&gt;&#xA;&lt;p&gt;三个部分：声明部分、转换规则、辅助函数。三个部分使用&lt;code&gt;%&lt;/code&gt;分隔。 &lt;br&gt;&#xA;声明部分包含名称声明及选项设置，其中&lt;code&gt;%{&lt;/code&gt;和&lt;code&gt;%}&lt;/code&gt;之间的内容会被原样复制到生成的c文件开头，通常放一些头文件及注释。&lt;br&gt;&#xA;&lt;img src=&#34;../blogImg/Flex2.PNG&#34; alt=&#34;图片2&#34;&gt;&lt;br&gt;&#xA;转换规则部分，每个规则由两部分组成：模式和动作，两者由空白分开。词法分析程序识别出某个模式后，执行该模式对应的动作。&lt;br&gt;&#xA;&lt;img src=&#34;../blogImg/Flex3.PNG&#34; alt=&#34;图片3&#34;&gt;&lt;br&gt;&#xA;辅助函数可以包含任一合法的c代码，这一部分的内容也会被复制到生成的c文件中。&lt;br&gt;&#xA;&lt;img src=&#34;../blogImg/Flex4.PNG&#34; alt=&#34;图片4&#34;&gt;&lt;br&gt;&#xA;&lt;img src=&#34;../blogImg/Flex5.PNG&#34; alt=&#34;图片5&#34;&gt;&lt;br&gt;&#xA;&lt;img src=&#34;../blogImg/Flex6.PNG&#34; alt=&#34;图片6&#34;&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;12-flex处理二义性模式&#34;&gt;1.2 Flex处理二义性模式&lt;/h2&gt;&#xA;&lt;p&gt;&lt;img src=&#34;../blogImg/Flex7.PNG&#34; alt=&#34;图片7&#34;&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title></title>
      <link>http://localhost:1313/posts/google-file-system/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/google-file-system/</guid>
      <description>&lt;p&gt;点击返回&lt;a href=&#34;https://2549141519.github.io/#/toc&#34;&gt;🔗我的博客文章目录&lt;/a&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;目录&#xA;{:toc}&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;!-- raw HTML omitted --&gt;&#xA;&lt;p&gt;paper &lt;a href=&#34;https://static.googleusercontent.com/media/research.google.com/en/us/archive/gfs-sosp2003.pdf&#34;&gt;link&lt;/a&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;1-google-file-systemgfs介绍&#34;&gt;1. Google File System(GFS)介绍&lt;/h1&gt;&#xA;&lt;p&gt;Google File System (GFS) 是谷歌为应对其大规模数据处理需求而开发的一种分布式文件系统。它的设计目标是高可扩展性和高容错性，能够在大量廉价的硬件设备上运行并提供高性能的数据存储解决方案。GFS 的特点是能够处理分布式数据密集型应用程序，适应如搜索引擎索引、大规模数据处理等需求。&lt;/p&gt;&#xA;&lt;h1 id=&#34;2-设计&#34;&gt;2. 设计&lt;/h1&gt;&#xA;&lt;h2 id=&#34;21-接口&#34;&gt;2.1 接口&lt;/h2&gt;&#xA;&lt;p&gt;GFS 提供了类似传统文件系统的接口，但没有实现标准的 API（例如 POSIX）。文件以路径名在目录中进行层次化组织，支持常见的文件操作，如创建、删除、打开、关闭、读取和写入。&lt;br&gt;&#xA;除此之外，GFS 提供了两个关键操作：快照（Snapshot） 和 记录追加（Record Append）。&lt;br&gt;&#xA;快照：&lt;br&gt;&#xA;这个功能可以以低成本创建文件或目录树的副本。它特别适合在不占用过多存储资源的情况下，快速保存文件的某个版本或整个目录结构的副本。这对于数据的备份和版本管理非常有用。&lt;br&gt;&#xA;记录追加：&lt;br&gt;&#xA;允许多个客户端同时向同一个文件追加数据，并确保每个客户端的追加操作是原子性的，即不会被其他客户端的操作中断。这种设计非常适合像多路合并结果和生产者-消费者队列等应用场景，多个客户端可以在没有额外锁定机制的情况下，同时追加数据到同一文件。&lt;/p&gt;&#xA;&lt;h2 id=&#34;22-架构&#34;&gt;2.2 架构&lt;/h2&gt;&#xA;&lt;p&gt;GFS架构包括三个核心组件：&lt;br&gt;&#xA;&lt;img src=&#34;../blogImg/gfs1.PNG&#34; alt=&#34;Alt text&#34;&gt;&lt;/p&gt;&#xA;&lt;h3 id=&#34;221-gfs-客户端&#34;&gt;2.2.1 GFS 客户端&lt;/h3&gt;&#xA;&lt;p&gt;GFS 客户端与应用程序相连，负责处理来自应用程序的文件系统操作请求。&lt;br&gt;&#xA;客户端不直接存储文件数据，而是通过与 GFS Master 和 GFS Chunkserver 的通信来读写数据。&lt;br&gt;&#xA;对于每个请求，客户端会首先联系 Master 来获取文件块的元数据信息（例如，文件名、块位置、块句柄），然后直接与 Chunkserver 进行数据交互。&lt;br&gt;&#xA;客户端会缓存一些元数据，减少与 Master 的交互次数，但不缓存实际文件数据，以避免缓存一致性问题。&lt;/p&gt;&#xA;&lt;h3 id=&#34;222-gfs-master&#34;&gt;2.2.2 GFS Master&lt;/h3&gt;&#xA;&lt;p&gt;GFS Master 是整个文件系统的核心管理组件，负责管理文件系统的元数据（如文件路径、块句柄与位置映射、访问控制等）。&lt;br&gt;&#xA;当客户端发出请求时，Master 会返回块的位置和相应的 Chunkserver 列表，而具体的读写操作则在客户端与 Chunkserver 之间直接进行。&#xA;Master 负责控制一些全局活动，比如块的租约管理（确保某个 Chunk 的副本一致性）、孤立块的垃圾回收、以及块在不同 Chunkserver 之间的迁移。&lt;br&gt;&#xA;GFS Master 与每个 Chunkserver 定期通过“心跳”消息进行通信，发送指令并收集 Chunkserver 的状态信息。&lt;/p&gt;</description>
    </item>
    <item>
      <title></title>
      <link>http://localhost:1313/posts/googletest-%E6%AF%94%E8%BE%83%E5%99%A8/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/googletest-%E6%AF%94%E8%BE%83%E5%99%A8/</guid>
      <description>&lt;p&gt;点击返回&lt;a href=&#34;https://2549141519.github.io/#/toc&#34;&gt;🔗我的博客文章目录&lt;/a&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;目录&#xA;{:toc}&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;!-- raw HTML omitted --&gt;&#xA;&lt;h1 id=&#34;1-比较器&#34;&gt;1. 比较器&lt;/h1&gt;&#xA;&lt;p&gt;本文介绍对于kdb中比较器&lt;a href=&#34;https://github.com/2549141519/kdb/src/db/comp.cpp&#34;&gt;&lt;code&gt;Comparator&lt;/code&gt;&lt;/a&gt;的单元测试。&lt;/p&gt;&#xA;&lt;p&gt;比较器实现逻辑如下：&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;解析键的长度： 代码首先从 left 和 right 字符串视图中读取键的长度（前面编码成 Varint 的 32 位整数）。通过 GetVarint32Ptr 函数从数据中解析出键的长度，并进行断言检查确保解析成功。&#xA;&#xA;提取键值： 通过从 left_key_len_ptr 和 right_key_len_ptr 解析出的长度，创建两个新的 std::string_view 分别表示 left 和 right 的键值。&#xA;&#xA;比较键值： 如果两个键值不同，直接比较它们的字符串值。std::string_view 支持字典序比较，代码通过 operator&amp;lt; 和 operator&amp;gt; 来进行比较，结果为 -1（left 小于 right）、1（left 大于 right）。&#xA;&#xA;如果键值相等： 当两个键值相等时，代码进一步解析并比较序列号。使用 GetVarint64Ptr 函数从键值之后的位置提取出 64 位序列号，并进行比较。最终返回比较结果。&#xA;&#xA;结果返回： 返回 -1 表示 left 小于 right，1 表示 left 大于 right，0 表示它们完全相同。&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;h1 id=&#34;2-googletest实现&#34;&gt;2. GoogleTest实现&lt;/h1&gt;&#xA;&lt;p&gt;为测试比较器，实现了&lt;a href=&#34;https://github.com/2549141519/kdb/src/db/test/comptest.cpp&#34;&gt;&lt;code&gt;ComparatorTest&lt;/code&gt;&lt;/a&gt;。&lt;/p&gt;&#xA;&lt;p&gt;为了模拟工作场景，在测试中实现了Set函数，用于将数据编码为sstable内部键的格式。&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;std::string Set(const std::shared_ptr&amp;lt;SetContext&amp;gt;&amp;amp; set_context) {&#xA;  auto key_size = VarintLength(set_context-&amp;gt;key.size());&#xA;  auto value_size = VarintLength(set_context-&amp;gt;value.size());&#xA;  auto sequence_number = VarintLength(set_context-&amp;gt;value.size());&#xA;&#xA;  std::string simple_set_str = fmt::format(&#xA;      &amp;#34;{}{}{}{}{}{}&amp;#34;, format32_vec[key_size], set_context-&amp;gt;key,&#xA;      format64_vec[sequence_number], kEmpty1Space,&#xA;      format32_vec[value_size], set_context-&amp;gt;value);&#xA;&#xA;  char* start_ptr = simple_set_str.data();&#xA;  start_ptr = EncodeVarint32(start_ptr, set_context-&amp;gt;key.size());&#xA;&#xA;  start_ptr += set_context-&amp;gt;key.size();&#xA;  start_ptr = EncodeVarint64(start_ptr, set_context-&amp;gt;number);&#xA;&#xA;  EncodeFixed8(start_ptr,ValueType::kTypeValue);&#xA;&#xA;  start_ptr += 1;&#xA;  EncodeVarint32(start_ptr, set_context-&amp;gt;value.size());&#xA;&#xA;  return simple_set_str;&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;实现了三个测试用例：&lt;/p&gt;</description>
    </item>
    <item>
      <title></title>
      <link>http://localhost:1313/posts/kdb-%E5%86%85%E5%AD%98%E6%B1%A0/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/kdb-%E5%86%85%E5%AD%98%E6%B1%A0/</guid>
      <description>&lt;p&gt;点击返回&lt;a href=&#34;https://2549141519.github.io/#/toc&#34;&gt;🔗我的博客文章目录&lt;/a&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;目录&#xA;{:toc}&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;!-- raw HTML omitted --&gt;&#xA;&lt;h1 id=&#34;1-代码实现&#34;&gt;1. 代码实现&lt;/h1&gt;&#xA;&lt;p&gt;kdb的内存池由&lt;a href=&#34;https://github.com/2549141519/kdb/blob/main/src/utils/arena.h&#34;&gt;arena.h&lt;/a&gt;和&lt;a href=&#34;https://github.com/2549141519/kdb/blob/main/src/utils/arena.cpp&#34;&gt;arena.cpp&lt;/a&gt;实现。&lt;/p&gt;&#xA;&lt;p&gt;实现内存池能够有效减少内存分配和释放的开销，提高系统性能。内存池的基本思想是预先分配一块大内存，并根据需要从中分配小块给应用程序使用，而不是每次都通过系统调用去动态分配和释放内存。&lt;/p&gt;&#xA;&lt;p&gt;代码实现了一个用于高效内存分配的类&lt;code&gt;Arena&lt;/code&gt;，通过预分配一块较大的内存块，并在其上进行内存分配。&lt;/p&gt;&#xA;&lt;h1 id=&#34;2-代码解析&#34;&gt;2. 代码解析&lt;/h1&gt;&#xA;&lt;h2 id=&#34;21-类的基本构造&#34;&gt;2.1 类的基本构造&lt;/h2&gt;&#xA;&lt;p&gt;&lt;code&gt;blocks_&lt;/code&gt;: 保存所有分配的内存块，每一个内存块的大小由 &lt;code&gt;kBlockSize&lt;/code&gt; 决定。所有分配的内存块的指针存储在一个 &lt;code&gt;std::vector&amp;lt;char*&amp;gt;&lt;/code&gt; 中。&lt;/p&gt;&#xA;&lt;p&gt;&lt;code&gt;alloc_ptr_&lt;/code&gt;: 当前分配指针，指向内存池中下一个可用的内存位置。&lt;/p&gt;&#xA;&lt;p&gt;&lt;code&gt;alloc_bytes_remaining_&lt;/code&gt;: 当前块剩余的内存大小，用来记录当前内存块中还可以分配的字节数。&lt;/p&gt;&#xA;&lt;p&gt;&lt;code&gt;memory_usage_&lt;/code&gt;: 用 &lt;code&gt;std::atomic&amp;lt;std::size_t&amp;gt;&lt;/code&gt; 类型记录总的内存使用量，适合多线程环境。&lt;/p&gt;&#xA;&lt;h2 id=&#34;22-构造和析构&#34;&gt;2.2 构造和析构&lt;/h2&gt;&#xA;&lt;p&gt;构造函数初始化了 &lt;code&gt;alloc_ptr_&lt;/code&gt;（当前指针）为 &lt;code&gt;nullptr&lt;/code&gt;，并将剩余内存字节数设为 0，表示当前没有可以分配的内存块。&lt;/p&gt;&#xA;&lt;p&gt;析构函数通过遍历 &lt;code&gt;blocks_&lt;/code&gt;，逐一释放已分配的内存块，避免内存泄漏。&lt;/p&gt;&#xA;&lt;h2 id=&#34;23-内存分配&#34;&gt;2.3 内存分配&lt;/h2&gt;&#xA;&lt;p&gt;&lt;code&gt;Allocate&lt;/code&gt;: 这是对外暴露的内存分配接口。如果当前内存块中剩余的空间足够满足需求，则直接分配，否则调用 &lt;code&gt;AllocateFallback&lt;/code&gt;，即分配新的内存块。&lt;/p&gt;&#xA;&lt;p&gt;&lt;code&gt;AllocateFallback&lt;/code&gt;: &lt;a href=&#34;#26-allocatefallback%E4%B8%AD%E7%9A%84%E5%9D%97%E5%A4%A7%E5%B0%8F%E7%AD%96%E7%95%A5&#34;&gt;AllocateFallback&lt;/a&gt;在当前块的剩余内存不足时调用。首先检查所需的字节数是否超过 &lt;code&gt;kBlockSize / 4&lt;/code&gt;（即 1024 字节）。如果超出，则直接为其分配一个新的块，大小为所需字节数；否则，分配一个常规的块，大小为 &lt;code&gt;kBlockSize&lt;/code&gt;（4096 字节），并从其中分配所需的内存。&lt;/p&gt;&#xA;&lt;p&gt;&lt;code&gt;AllocateNewBlock&lt;/code&gt;: 该函数用于分配一个新的内存块。分配完新块后，存储块指针，并更新总的内存使用量。注意这里内存使用量增加的值是新块大小加上存储块指针的大小。&lt;/p&gt;&#xA;&lt;h2 id=&#34;24-内存对齐&#34;&gt;2.4 内存对齐&lt;/h2&gt;&#xA;&lt;p&gt;&lt;code&gt;AllocateAligned&lt;/code&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;25-多线程支持&#34;&gt;2.5 多线程支持&lt;/h2&gt;&#xA;&lt;p&gt;&lt;code&gt;memory_usage_ &lt;/code&gt;使用了 &lt;code&gt;std::atomic&lt;/code&gt; 来保证在多线程环境下的安全访问。这意味着多个线程可以同时分配内存。&lt;/p&gt;&#xA;&lt;p&gt;但在实现时，默认假设了&lt;code&gt;Arena&lt;/code&gt;主要用于单线程环境，因此其他部分（如&lt;code&gt;alloc_ptr_ &lt;/code&gt;和&lt;code&gt;alloc_bytes_remaining_ &lt;/code&gt;）没有使用锁机制。&lt;/p&gt;&#xA;&lt;h2 id=&#34;26-allocatefallback中的块大小策略&#34;&gt;2.6 AllocateFallback中的块大小策略&lt;/h2&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;char *Arena::AllocateFallback(std::size_t bytes)&#xA;    {&#xA;        if (bytes &amp;gt; kBlockSize / 4) &#xA;        {&#xA;            char* result = AllocateNewBlock(bytes);&#xA;            return result;&#xA;        }&#xA;        alloc_ptr_ = AllocateNewBlock(kBlockSize);&#xA;        alloc_bytes_remaining_ = kBlockSize;&#xA;&#xA;        char* result = alloc_ptr_;&#xA;        alloc_ptr_ += bytes;&#xA;        alloc_bytes_remaining_ -= bytes;&#xA;        return result;&#xA;    }&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;261-内存块小于或等于-kblocksize--4-的情况&#34;&gt;2.6.1 内存块小于或等于 &lt;code&gt;kBlockSize / 4 &lt;/code&gt;的情况&lt;/h3&gt;&#xA;&lt;p&gt;对于小于等于 1024 字节的分配请求，&lt;code&gt;Arena &lt;/code&gt;会预先分配一个较大的内存块（大小为 4096 字节），并将多次分配集中在同一块内存中。&lt;/p&gt;</description>
    </item>
    <item>
      <title></title>
      <link>http://localhost:1313/posts/kdb-%E8%B7%B3%E8%A1%A8/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/kdb-%E8%B7%B3%E8%A1%A8/</guid>
      <description>&lt;p&gt;点击返回&lt;a href=&#34;https://2549141519.github.io/#/toc&#34;&gt;🔗我的博客文章目录&lt;/a&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;目录&#xA;{:toc}&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;!-- raw HTML omitted --&gt;&#xA;&lt;h1 id=&#34;1-跳表的定义&#34;&gt;1. 跳表的定义&lt;/h1&gt;&#xA;&lt;p&gt;跳表（SkipList）是一种用于维护有序元素的链表结构，通过在链表基础上增加多层索引，实现快速查找和插入操作。跳表的层数是随机生成的，最上层节点较少，底层节点最多。&lt;br&gt;&#xA;每个节点拥有多个指向下一个节点的指针，不同的层级允许快速跳过多个节点。&lt;br&gt;&#xA;通过多层索引，跳表的查找和插入复杂度可以达到 O(logn)，接近二分查找的性能。&lt;br&gt;&#xA;kdb的跳表在&lt;a href=&#34;https://github.com/2549141519/kdb/blob/main/src/include/skiplist.h&#34;&gt;skiplist.h&lt;/a&gt;中实现。&lt;/p&gt;&#xA;&lt;h2 id=&#34;12-模板类定义&#34;&gt;1.2 模板类定义&lt;/h2&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;template&amp;lt;typename Key, class Comparator&amp;gt;&#xA;class SkipList {&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;code&gt;Key&lt;/code&gt;:跳表存储的键类型，可以是任何类型。&lt;br&gt;&#xA;&lt;code&gt;Comparator&lt;/code&gt;:比较器，用于比较&lt;code&gt;Key&lt;/code&gt;类型的值。跳表是有序的，因此需要一个比较器来确定键的顺序。&lt;/p&gt;&#xA;&lt;h2 id=&#34;13-内部节点结构node&#34;&gt;1.3 内部节点结构&lt;code&gt;Node&lt;/code&gt;&lt;/h2&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;struct Node {&#xA;  Key const key;&#xA;  std::atomic&amp;lt;Node*&amp;gt; next_[1];  &#xA;};&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;每个节点存储一个键值 &lt;code&gt;key&lt;/code&gt; 和一个 &lt;code&gt;next_&lt;/code&gt; 指针数组，&lt;code&gt;next_ &lt;/code&gt;的大小根据节点的高度动态分配。每个指针指向跳表中不同层的下一个节点，跳表的结构通过这些指针数组实现多层索引。&lt;br&gt;&#xA;使用&lt;code&gt;atomic&lt;/code&gt;类型确保无锁操作的线程安全性。&lt;/p&gt;&#xA;&lt;h1 id=&#34;2-重要操作&#34;&gt;2. 重要操作&lt;/h1&gt;&#xA;&lt;h2 id=&#34;21-插入操作insert&#34;&gt;2.1 插入操作&lt;code&gt;Insert&lt;/code&gt;&lt;/h2&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;void SkipList&amp;lt;Key, Comparator&amp;gt;::Insert(const Key&amp;amp; key) {&#xA;    Node* prev[KMaxHeight];&#xA;    Node* n = FindGreaterOrEqual(key, prev);  // 找到插入位置   &#xA;    assert(n == nullptr || !Equal(key, n-&amp;gt;key));  // 跳表中不允许有重复键&#xA;    int height = RandomHeight();  // 随机生成节点的高度&#xA;    if (height &amp;gt; GetMaxHeight()) {&#xA;        for (int i = GetMaxHeight(); i &amp;lt; height; i++) {&#xA;            prev[i] = head_;&#xA;        }&#xA;        max_height_.store(height, std::memory_order_relaxed);&#xA;    }&#xA;    n = NewNode(key, height);  // 创建新节点&#xA;    for (int i = 0; i &amp;lt; height; i++) {&#xA;        n-&amp;gt;NoBarrier_SetNext(i, prev[i]-&amp;gt;NoBarrier_Next(i));  // 连接新节点&#xA;        prev[i]-&amp;gt;SetNext(i, n);  // 设置前一个节点的下一指针&#xA;    }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;查找插入位置：&lt;br&gt;&#xA;调用 &lt;a href=&#34;#22-%E6%9F%A5%E6%89%BE%E6%93%8D%E4%BD%9Cfindgreaterorequal&#34;&gt;&lt;code&gt;FindGreaterOrEqual&lt;/code&gt;&lt;/a&gt; 方法，找到跳表中第一个大于等于 &lt;code&gt;key&lt;/code&gt; 的位置。&lt;code&gt;prev&lt;/code&gt; 数组存储每一层插入位置前的节点。&lt;/p&gt;</description>
    </item>
    <item>
      <title></title>
      <link>http://localhost:1313/posts/mapreduce-for-nosql/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/mapreduce-for-nosql/</guid>
      <description>&lt;p&gt;点击返回&lt;a href=&#34;https://2549141519.github.io/#/toc&#34;&gt;🔗我的博客文章目录&lt;/a&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;目录&#xA;{:toc}&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;!-- raw HTML omitted --&gt;&#xA;&lt;h1 id=&#34;1-前言&#34;&gt;1. 前言&lt;/h1&gt;&#xA;&lt;p&gt;本文将实现MapReduce和NoSQL数据库的交互，统计单词出现次数。&#xA;NoSQL数据库选用redis6.0，以下是redis操作的一些命令(我设置的redis6.0端口为6380)：&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;sudo redis-server /etc/redis/redis.conf&lt;br&gt;&#xA;//启动redis6.0实例&lt;br&gt;&#xA;redis-cli -p 6380&lt;br&gt;&#xA;//连接redis6.0实例,6380为端口号&lt;br&gt;&#xA;redis-cli -p 6380 KEYS &amp;ldquo;key*&amp;rdquo; | xargs redis-cli -p 6380 DEL&lt;br&gt;&#xA;//删除redis6.0实例中以key*为前缀的所有key&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;h1 id=&#34;2-使用go语言实现&#34;&gt;2. 使用go语言实现&lt;/h1&gt;&#xA;&lt;h2 id=&#34;21-生成随机数据并存入redis&#34;&gt;2.1 生成随机数据并存入Redis&lt;/h2&gt;&#xA;&lt;p&gt;随机生成1万个单词，并写入redis数据库中：&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;package main&lt;br&gt;&#xA;import (&lt;br&gt;&#xA;&amp;ldquo;context&amp;rdquo;&lt;br&gt;&#xA;&amp;ldquo;fmt&amp;rdquo;&lt;br&gt;&#xA;&amp;ldquo;math/rand&amp;rdquo;&lt;br&gt;&#xA;&amp;ldquo;time&amp;rdquo;&lt;br&gt;&#xA;&amp;ldquo;github.com/go-redis/redis/v8&amp;rdquo;&lt;br&gt;&#xA;)&lt;br&gt;&#xA;// 生成随机字符串&lt;br&gt;&#xA;func randomString(n int) string {&lt;br&gt;&#xA;letters := []rune(&amp;ldquo;abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ&amp;rdquo;)&lt;br&gt;&#xA;s := make([]rune, n)&lt;br&gt;&#xA;for i := range s {&lt;br&gt;&#xA;s[i] = letters[rand.Intn(len(letters))]&lt;br&gt;&#xA;}&lt;br&gt;&#xA;return string(s)&lt;br&gt;&#xA;}&lt;br&gt;&#xA;// 生成随机数据并存入Redis&lt;br&gt;&#xA;func generateDataAndSaveToRedis(rdb *redis.Client, count int) {&lt;br&gt;&#xA;ctx := context.Background()&lt;br&gt;&#xA;for i := 0; i &amp;lt; count; i++ {&lt;br&gt;&#xA;key := fmt.Sprintf(&amp;ldquo;key%d&amp;rdquo;, i)&lt;br&gt;&#xA;value := randomString(3) // 生成长度为3的随机字符串&lt;br&gt;&#xA;err := rdb.Set(ctx, key, value, 0).Err()&lt;br&gt;&#xA;if err != nil {&lt;br&gt;&#xA;panic(err)&lt;br&gt;&#xA;}&lt;br&gt;&#xA;}&lt;br&gt;&#xA;fmt.Printf(&amp;ldquo;Successfully generated and saved %d random data entries to Redis.\n&amp;rdquo;, count)&lt;br&gt;&#xA;}&lt;br&gt;&#xA;func main() {&lt;br&gt;&#xA;// 设置随机种子&lt;br&gt;&#xA;rand.Seed(time.Now().UnixNano())&lt;br&gt;&#xA;// 连接到Redis&lt;br&gt;&#xA;rdb := redis.NewClient(&amp;amp;redis.Options{&lt;br&gt;&#xA;Addr: &amp;ldquo;localhost:6380&amp;rdquo;, // Redis服务器地址&lt;br&gt;&#xA;DB:   0,                // 使用默认的DB&lt;br&gt;&#xA;})&lt;br&gt;&#xA;// 生成10000个随机数据并存入Redis&lt;br&gt;&#xA;generateDataAndSaveToRedis(rdb, 10000)&lt;br&gt;&#xA;}&lt;/p&gt;</description>
    </item>
    <item>
      <title></title>
      <link>http://localhost:1313/posts/mapreduce/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/mapreduce/</guid>
      <description>&lt;p&gt;点击返回&lt;a href=&#34;https://2549141519.github.io/#/toc&#34;&gt;🔗我的博客文章目录&lt;/a&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;目录&#xA;{:toc}&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;!-- raw HTML omitted --&gt;&#xA;&lt;p&gt;paper &lt;a href=&#34;https://static.googleusercontent.com/media/research.google.com/en//archive/mapreduce-osdi04.pdf&#34;&gt;link&lt;/a&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;1介绍&#34;&gt;1.介绍&lt;/h1&gt;&#xA;&lt;p&gt;MapReduce 是一种用于处理和生成大规模数据集的编程模型。它将数据处理分为两个主要阶段：Map 和 Reduce，从而实现对大数据的并行计算和分布式处理。MapReduce的设计目标是能够在计算机集群上高效处理TB级甚至PB级的数据集。&lt;/p&gt;&#xA;&lt;h1 id=&#34;2编程模型&#34;&gt;2.编程模型&lt;/h1&gt;&#xA;&lt;p&gt;例如大型文档集合中每个单词出现次数的问题，我们可以使用MapReduce处理，下文将默认处理该问题。&lt;/p&gt;&#xA;&lt;h2 id=&#34;21example&#34;&gt;2.1Example&lt;/h2&gt;&#xA;&lt;p&gt;伪代码：&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;map(String key, String value):&lt;br&gt;&#xA;// key: document name&lt;br&gt;&#xA;// value: document contents&lt;br&gt;&#xA;for each word w in value:&lt;br&gt;&#xA;EmitIntermediate(w, &amp;ldquo;1&amp;rdquo;);&lt;br&gt;&#xA;reduce(String key, Iterator values):&lt;br&gt;&#xA;// key: a word&lt;br&gt;&#xA;// values: a list of counts&lt;br&gt;&#xA;int result = 0;&lt;br&gt;&#xA;for each v in values:&lt;br&gt;&#xA;result += ParseInt(v);&lt;br&gt;&#xA;Emit(AsString(result));&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;p&gt;map函数发出每个单词加上一个相关的出现次数计数(在这个简单的示例中只有&amp;rsquo; 1 &amp;lsquo;)。reduce函数将针对特定单词发出的所有计数求和。&#xA;mapTask函数具体实现：&lt;/p&gt;</description>
    </item>
    <item>
      <title></title>
      <link>http://localhost:1313/posts/miniob-b&#43;%E6%A0%91/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/miniob-b&#43;%E6%A0%91/</guid>
      <description>&lt;p&gt;点击返回&lt;a href=&#34;https://2549141519.github.io/#/toc&#34;&gt;🔗我的博客文章目录&lt;/a&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;目录&#xA;{:toc}&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;!-- raw HTML omitted --&gt;&#xA;&lt;h1 id=&#34;1-b树介绍&#34;&gt;1. B+树介绍&lt;/h1&gt;&#xA;&lt;p&gt;B+树是一种平衡的树形数据结构，通常用于数据库和文件系统等需要频繁进行磁盘存取的大型数据管理系统。它是B树的扩展版本，具有更高效的查询和范围查询能力。B+树的设计初衷是为了优化磁盘存取的效率，因而在处理大规模数据时非常适合。&lt;/p&gt;&#xA;&lt;h2 id=&#34;11-b树的结构特点&#34;&gt;1.1 B+树的结构特点&lt;/h2&gt;&#xA;&lt;p&gt;所有关键字都出现在叶子节点：&lt;br&gt;&#xA;B+树与B树的主要区别之一是，B+树中所有的关键字都存储在叶子节点中，内部节点只存储索引信息。叶子节点按照关键字的顺序排列，并通过指针连接，形成一个有序的链表。&lt;/p&gt;&#xA;&lt;p&gt;内节点只存储索引而不存储数据：&lt;br&gt;&#xA;B+树的非叶子节点（内节点）不存储实际数据，它们只是用于指引查询路径的索引，指向子树或叶子节点。&lt;/p&gt;&#xA;&lt;p&gt;所有叶子节点在同一层：&lt;br&gt;&#xA;B+树是高度平衡的，即所有叶子节点都在同一层，确保查询操作的时间复杂度为&lt;code&gt;O(log n)&lt;/code&gt;，其中&lt;code&gt;n&lt;/code&gt;是数据项的总数。&lt;/p&gt;&#xA;&lt;p&gt;叶子节点链表结构：&lt;br&gt;&#xA;叶子节点之间是有序链表，意味着在进行范围查询时，可以通过叶子节点的顺序访问快速获取一组连续的结果。&lt;/p&gt;&#xA;&lt;h2 id=&#34;12-b树的优点&#34;&gt;1.2 B+树的优点&lt;/h2&gt;&#xA;&lt;p&gt;范围查询性能优异：&lt;br&gt;&#xA;由于叶子节点之间的链表结构，B+树在处理范围查询时表现极为优秀，可以从起始位置沿着链表顺序读取。&lt;/p&gt;&#xA;&lt;p&gt;磁盘I/O优化：&lt;br&gt;&#xA;B+树的设计目标是减少磁盘I/O操作。内节点不存储实际数据，因此可以将更多的索引节点放入内存中，减少从磁盘读取数据的次数。&lt;/p&gt;&#xA;&lt;p&gt;平衡性：&lt;br&gt;&#xA;B+树是一种平衡树，保证了插入、删除、查询操作的时间复杂度始终保持在&lt;code&gt;O(log n)&lt;/code&gt;。&lt;/p&gt;&#xA;&lt;p&gt;存储密度高：&lt;br&gt;&#xA;由于内节点不存储数据，B+树可以将更多的索引节点放入内存，从而有效利用系统的缓存。&lt;/p&gt;&#xA;&lt;h2 id=&#34;13-b树的应用场景&#34;&gt;1.3 B+树的应用场景&lt;/h2&gt;&#xA;&lt;p&gt;数据库系统：&lt;br&gt;&#xA;在关系型数据库中，B+树常用于实现索引，如MySQL中的InnoDB存储引擎就使用B+树作为其主键索引结构。&lt;/p&gt;&#xA;&lt;p&gt;文件系统：&lt;br&gt;&#xA;一些文件系统，如NTFS，也采用B+树来管理文件和目录数据。&lt;/p&gt;&#xA;&lt;p&gt;大规模数据存储：&lt;br&gt;&#xA;B+树特别适合需要在磁盘中管理大规模数据的场景，能够很好地处理磁盘I/O。&lt;/p&gt;&#xA;&lt;h2 id=&#34;14-b树与b树的区别&#34;&gt;1.4 B+树与B树的区别&lt;/h2&gt;&#xA;&lt;p&gt;数据存储位置：&lt;br&gt;&#xA;B树的数据既存储在内节点也存储在叶子节点，而B+树的数据只存储在叶子节点。&lt;/p&gt;&#xA;&lt;p&gt;范围查询效率：&lt;br&gt;&#xA;由于B+树的叶子节点构成链表结构，进行范围查询时可以直接从链表中遍历，而B树则需要更多的树遍历操作。&lt;/p&gt;&#xA;&lt;p&gt;节点结构：&lt;br&gt;&#xA;B+树的内节点更为紧凑，因为它们只存储索引，而B树的内节点存储索引和数据。&lt;/p&gt;&#xA;&lt;h1 id=&#34;2-b树在miniob的应用&#34;&gt;2. B+树在miniob的应用&lt;/h1&gt;&#xA;&lt;h2 id=&#34;21-b树的结构与节点&#34;&gt;2.1 B+树的结构与节点&lt;/h2&gt;&#xA;&lt;h3 id=&#34;211-indexfileheader&#34;&gt;2.1.1 &lt;code&gt;IndexFileHeader&lt;/code&gt;&lt;/h3&gt;&#xA;&lt;p&gt;&lt;code&gt;IndexFileHeader&lt;/code&gt;：&lt;br&gt;&#xA;用于存储 B+ 树的元数据，包括根节点页面编号、内部节点和叶子节点的最大大小、属性长度等。&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;struct IndexFileHeader&#xA;{&#xA;  IndexFileHeader()&#xA;  {&#xA;    memset(this, 0, sizeof(IndexFileHeader));&#xA;    root_page = BP_INVALID_PAGE_NUM;&#xA;  }&#xA;  PageNum  root_page;          ///&amp;lt; 根节点在磁盘中的页号&#xA;  int32_t  internal_max_size;  ///&amp;lt; 内部节点最大的键值对数&#xA;  int32_t  leaf_max_size;      ///&amp;lt; 叶子节点最大的键值对数&#xA;  int32_t  attr_length;        ///&amp;lt; 键值的长度&#xA;  int32_t  key_length;         ///&amp;lt; attr length + sizeof(RID)&#xA;  AttrType attr_type;          ///&amp;lt; 键值的类型&#xA;&#xA;  const string to_string() const&#xA;  {&#xA;    stringstream ss;&#xA;&#xA;    ss &amp;lt;&amp;lt; &amp;#34;attr_length:&amp;#34; &amp;lt;&amp;lt; attr_length &amp;lt;&amp;lt; &amp;#34;,&amp;#34;&#xA;       &amp;lt;&amp;lt; &amp;#34;key_length:&amp;#34; &amp;lt;&amp;lt; key_length &amp;lt;&amp;lt; &amp;#34;,&amp;#34;&#xA;       &amp;lt;&amp;lt; &amp;#34;attr_type:&amp;#34; &amp;lt;&amp;lt; attr_type_to_string(attr_type) &amp;lt;&amp;lt; &amp;#34;,&amp;#34;&#xA;       &amp;lt;&amp;lt; &amp;#34;root_page:&amp;#34; &amp;lt;&amp;lt; root_page &amp;lt;&amp;lt; &amp;#34;,&amp;#34;&#xA;       &amp;lt;&amp;lt; &amp;#34;internal_max_size:&amp;#34; &amp;lt;&amp;lt; internal_max_size &amp;lt;&amp;lt; &amp;#34;,&amp;#34;&#xA;       &amp;lt;&amp;lt; &amp;#34;leaf_max_size:&amp;#34; &amp;lt;&amp;lt; leaf_max_size &amp;lt;&amp;lt; &amp;#34;;&amp;#34;;&#xA;&#xA;    return ss.str();&#xA;  }&#xA;};&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;code&gt;PageNum root_page&lt;/code&gt;：&lt;br&gt;&#xA;该变量存储了根节点在磁盘中的页号，用于指示B+树在文件系统中的存储位置。&lt;code&gt;BP_INVALID_PAGE_NUM&lt;/code&gt; 表示一个无效的页号。&lt;br&gt;&#xA;&lt;code&gt;int32_t internal_max_size&lt;/code&gt;：&lt;br&gt;&#xA;这是内部节点中可以存储的最大键值对数。对于一个B+树的内部节点而言，它存储的是索引信息和指向子节点的指针，因此这个值决定了内部节点的分裂和合并策略。&lt;br&gt;&#xA;&lt;code&gt;int32_t leaf_max_size&lt;/code&gt;：&lt;br&gt;&#xA;叶子节点可以存储的最大键值对数。叶子节点中存储的是实际的数据，定义了B+树中叶子节点的存储容量，影响了B+树的深度和查找效率。&lt;br&gt;&#xA;&lt;code&gt;int32_t attr_length&lt;/code&gt;：&lt;br&gt;&#xA;键值的长度，通常是指数据库中索引字段的长度。它决定了每个键在树中占据的空间大小。&lt;br&gt;&#xA;&lt;code&gt;int32_t key_length&lt;/code&gt;：&lt;br&gt;&#xA;该变量表示键值的总长度，即 &lt;code&gt;attr_length&lt;/code&gt; 加上 &lt;code&gt;sizeof(RID)&lt;/code&gt;，其中 &lt;code&gt;RID &lt;/code&gt;是数据库中的记录标识符（Record ID）。这样可以存储索引键及其对应的记录位置。&lt;br&gt;&#xA;&lt;code&gt;AttrType attr_type&lt;/code&gt;：&lt;br&gt;&#xA;键值的类型，定义了索引所依赖的属性类型（如整数、字符串等）。该枚举类型用于描述键值的实际数据类型。&lt;/p&gt;</description>
    </item>
    <item>
      <title></title>
      <link>http://localhost:1313/posts/miniob-bufferpool/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/miniob-bufferpool/</guid>
      <description>&lt;p&gt;点击返回&lt;a href=&#34;https://2549141519.github.io/#/toc&#34;&gt;🔗我的博客文章目录&lt;/a&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;目录&#xA;{:toc}&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;!-- raw HTML omitted --&gt;&#xA;&lt;h1 id=&#34;1-buffer-pool缓冲池介绍&#34;&gt;1. Buffer Pool（缓冲池）介绍&lt;/h1&gt;&#xA;&lt;p&gt;Buffer Pool 是数据库管理系统中用于管理和优化内存使用的一个关键组件。其主要作用是将磁盘上的数据页缓存在内存中，以减少对磁盘的访问次数，从而提高数据库的性能。大多数现代数据库（如 MySQL、PostgreSQL、OceanBase 等）都使用了 Buffer Pool 来加速读写操作。&lt;/p&gt;&#xA;&lt;h2 id=&#34;11-buffer-pool-的核心组件&#34;&gt;1.1 Buffer Pool 的核心组件&lt;/h2&gt;&#xA;&lt;p&gt;Page (页)：&#xA;数据库以页（page）为单位管理数据。页是数据库中数据的最小管理单位，通常大小为4KB、8KB或16KB（具体取决于数据库的配置）。&lt;br&gt;&#xA;Buffer Pool 中的每一个缓存块都会缓存一个磁盘上的数据页，当客户端请求某个数据时，数据库首先会检查该数据页是否已经在 Buffer Pool 中，如果在，就可以直接从内存读取数据；如果不在，则需要从磁盘加载该页到 Buffer Pool 中。&lt;br&gt;&#xA;Buffer Frame (缓存帧)：&lt;br&gt;&#xA;Buffer Pool 由多个 Buffer Frame 组成，每个 Frame 都可以存储一个数据库页。当数据库需要访问某个数据页时，如果该页已经在某个 Frame 中，那么这个 Frame 就会被直接返回。否则，将分配一个空的或可重用的 Frame 用来存储从磁盘读取的页。&lt;br&gt;&#xA;Page Table (页表)：&lt;br&gt;&#xA;Buffer Pool 维护一个页表（Page Table），用于记录每个数据页在 Buffer Pool 中的位置。通过页表，数据库可以快速找到某个数据页是否已经被缓存，以及它位于 Buffer Pool 中的哪个缓存帧。&lt;br&gt;&#xA;Replacement Policy (替换策略)：&lt;br&gt;&#xA;由于内存有限，Buffer Pool 无法无限制地缓存所有数据。当 Buffer Pool 已满时，数据库需要根据某种替换策略将某些页从 Buffer Pool 中移除，以便为新加载的页腾出空间。常见的替换策略包括：&lt;br&gt;&#xA;&lt;strong&gt;LRU (Least Recently Used)：最久未使用的页会被优先替换。&lt;/strong&gt;&lt;br&gt;&#xA;&lt;strong&gt;MRU (Most Recently Used)：最近使用的页会被优先替换。&lt;/strong&gt;&lt;br&gt;&#xA;&lt;strong&gt;LFU (Least Frequently Used)：最少被访问的页会被优先替换。&lt;/strong&gt;&lt;br&gt;&#xA;Dirty Page (脏页)：&lt;br&gt;&#xA;当某个页的数据被修改时，该页称为脏页。脏页表示 Buffer Pool 中的数据已经与磁盘上的数据不一致，需要在合适的时候将脏页写回磁盘以保证数据的持久性。&lt;br&gt;&#xA;数据库系统会通过后台线程定期地将脏页刷回到磁盘，或者在某些条件下强制刷新。&lt;/p&gt;</description>
    </item>
    <item>
      <title></title>
      <link>http://localhost:1313/posts/miniob-debug-sql%E8%AF%AD%E5%8F%A5/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/miniob-debug-sql%E8%AF%AD%E5%8F%A5/</guid>
      <description>&lt;p&gt;点击返回&lt;a href=&#34;https://2549141519.github.io/#/toc&#34;&gt;🔗我的博客文章目录&lt;/a&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;目录&#xA;{:toc}&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;!-- raw HTML omitted --&gt;&#xA;&lt;h1 id=&#34;1-使用miniob的debug&#34;&gt;1. 使用miniob的DEBUG&lt;/h1&gt;&#xA;&lt;p&gt;miniob已经实现了&lt;code&gt;launch.json&lt;/code&gt;和&lt;code&gt;tasks.json&lt;/code&gt;，可以直接调试。&lt;br&gt;&#xA;在&lt;code&gt;miniob/src/observer/net/sql_task_handler.cpp&lt;/code&gt;中，直接找到&lt;code&gt;handle_sql&lt;/code&gt;函数，打断点，调试即可。&lt;br&gt;&#xA;&lt;img src=&#34;../blogImg/debug2.PNG&#34; alt=&#34;图片2&#34;&gt;&lt;br&gt;&#xA;&lt;img src=&#34;../blogImg/debug3.PNG&#34; alt=&#34;图片3&#34;&gt;&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;RC SqlTaskHandler::handle_sql(SQLStageEvent *sql_event)&#xA;{&#xA;  RC rc = query_cache_stage_.handle_request(sql_event);&#xA;  if (OB_FAIL(rc)) {&#xA;    LOG_TRACE(&amp;#34;failed to do query cache. rc=%s&amp;#34;, strrc(rc));&#xA;    return rc;&#xA;  }&#xA;&#xA;  rc = parse_stage_.handle_request(sql_event);&#xA;  if (OB_FAIL(rc)) {&#xA;    LOG_TRACE(&amp;#34;failed to do parse. rc=%s&amp;#34;, strrc(rc));&#xA;    return rc;&#xA;  }&#xA;&#xA;  rc = resolve_stage_.handle_request(sql_event);&#xA;  if (OB_FAIL(rc)) {&#xA;    LOG_TRACE(&amp;#34;failed to do resolve. rc=%s&amp;#34;, strrc(rc));&#xA;    return rc;&#xA;  }&#xA;&#xA;  rc = optimize_stage_.handle_request(sql_event);&#xA;  if (rc != RC::UNIMPLEMENTED &amp;amp;&amp;amp; rc != RC::SUCCESS) {&#xA;    LOG_TRACE(&amp;#34;failed to do optimize. rc=%s&amp;#34;, strrc(rc));&#xA;    return rc;&#xA;  }&#xA;&#xA;  rc = execute_stage_.handle_request(sql_event);&#xA;  if (OB_FAIL(rc)) {&#xA;    LOG_TRACE(&amp;#34;failed to do execute. rc=%s&amp;#34;, strrc(rc));&#xA;    return rc;&#xA;  }&#xA;&#xA;  return rc;&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;h1 id=&#34;2-调试&#34;&gt;2. 调试&lt;/h1&gt;&#xA;&lt;p&gt;打断点：&lt;br&gt;&#xA;&lt;img src=&#34;../blogImg/debug1.PNG&#34; alt=&#34;图1&#34;&gt;&lt;br&gt;&#xA;开始调试：&lt;br&gt;&#xA;键入&lt;code&gt;CREATE TABLE TEST (ID int)&lt;/code&gt;,创建一个名为“TEST”的表,表含一个名为“ID”的整型字段。 &lt;br&gt;&#xA;&lt;img src=&#34;../blogImg/debug4.PNG&#34; alt=&#34;图4&#34;&gt;&lt;br&gt;&#xA;解析阶段：&lt;br&gt;&#xA;&lt;img src=&#34;../blogImg/debug5.PNG&#34; alt=&#34;图5&#34;&gt;&lt;br&gt;&#xA;解析完成后，生成语法树SQLNode：&lt;br&gt;&#xA;&lt;img src=&#34;../blogImg/debug6.PNG&#34; alt=&#34;图6&#34;&gt;&lt;br&gt;&#xA;&lt;code&gt;CREATE TABLE&lt;/code&gt;操作没有优化计划，返回&lt;code&gt;UNIMPLEMENTED&lt;/code&gt;，直接进入执行阶段。&lt;br&gt;&#xA;&lt;img src=&#34;../blogImg/debug7.PNG&#34; alt=&#34;图7&#34;&gt;&lt;br&gt;&#xA;进入执行器执行，输出SUCCESS。&lt;br&gt;&#xA;&lt;img src=&#34;../blogImg/debug8.PNG&#34; alt=&#34;图8&#34;&gt;&lt;br&gt;&#xA;编译结束后执行&lt;code&gt;SHOW TABLES&lt;/code&gt;命令查看所有表，确保成功创建表：&lt;br&gt;&#xA;&lt;img src=&#34;../blogImg/debug9.PNG&#34; alt=&#34;图9&#34;&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title></title>
      <link>http://localhost:1313/posts/miniob-sql%E8%AF%AD%E5%8F%A5%E6%89%A7%E8%A1%8C%E6%B5%81%E7%A8%8B/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/miniob-sql%E8%AF%AD%E5%8F%A5%E6%89%A7%E8%A1%8C%E6%B5%81%E7%A8%8B/</guid>
      <description>&lt;p&gt;点击返回&lt;a href=&#34;https://2549141519.github.io/#/toc&#34;&gt;🔗我的博客文章目录&lt;/a&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;目录&#xA;{:toc}&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;!-- raw HTML omitted --&gt;&#xA;&lt;h1 id=&#34;1-sql语句执行流程&#34;&gt;1. SQL语句执行流程&lt;/h1&gt;&#xA;&lt;p&gt;在MiniOB项目中，SQL语句的执行过程如下：&lt;/p&gt;&#xA;&lt;h2 id=&#34;11-sql解析&#34;&gt;1.1 SQL解析&lt;/h2&gt;&#xA;&lt;p&gt;当SQL语句被输入时，首先经过词法和语法分析器（如 Flex 和 Bison）解析成&lt;code&gt;SQLNode&lt;/code&gt;。&lt;code&gt;SQLNode&lt;/code&gt;是抽象语法树（AST）的组成部分，它表示SQL语句中的不同结构元素。&lt;/p&gt;&#xA;&lt;h2 id=&#34;12-sqlnode转换为stmt&#34;&gt;1.2 SQLNode转换为Stmt&lt;/h2&gt;&#xA;&lt;p&gt;在&lt;code&gt;Stmt&lt;/code&gt;模块中，&lt;code&gt;SQLNode&lt;/code&gt; 会被简单地判断，并根据不同的 SQL 语句类型（如&lt;code&gt; SELECT&lt;/code&gt;、&lt;code&gt;INSERT&lt;/code&gt;、&lt;code&gt;UPDATE&lt;/code&gt; 等）生成相应的&lt;code&gt;Stmt&lt;/code&gt;对象。&lt;code&gt;Stmt&lt;/code&gt; 是逻辑语义的更高级别表示，用于执行逻辑分析和进一步优化。&lt;/p&gt;&#xA;&lt;h2 id=&#34;13-生成逻辑算子&#34;&gt;1.3 生成逻辑算子&lt;/h2&gt;&#xA;&lt;p&gt;&lt;code&gt;Stmt&lt;/code&gt;对象会被传递到逻辑分析阶段，生成对应的逻辑算子。逻辑算子表示操作的高层次语义（例如表扫描、连接、筛选等），但此时并不关心具体的执行方式。&lt;/p&gt;&#xA;&lt;h2 id=&#34;14-生成物理算子&#34;&gt;1.4 生成物理算子&lt;/h2&gt;&#xA;&lt;p&gt;在查询优化阶段，逻辑算子会被优化器转换为物理算子。物理算子代表查询的实际执行策略，例如顺序扫描、索引扫描、哈希连接等。优化器的作用是选择最优的执行方式，以提高查询效率。物理算子与存储模块之间有着直接的关联。物理算子负责执行具体的操作，而这些操作往往涉及对数据库中数据的实际读取、写入、更新和删除，这些操作需要与存储模块交互。&lt;/p&gt;&#xA;&lt;h2 id=&#34;15-执行&#34;&gt;1.5 执行&lt;/h2&gt;&#xA;&lt;p&gt;物理算子会由执行器执行，执行器根据物理算子生成的数据流，访问存储层并返回结果。&lt;/p&gt;&#xA;&lt;h1 id=&#34;2-查询优化&#34;&gt;2. 查询优化&lt;/h1&gt;&#xA;&lt;p&gt;查询优化 是在逻辑算子生成后和物理算子生成前执行的。这一步优化器根据逻辑算子生成多个执行方案（物理算子），并选择最优的执行方式。&lt;br&gt;&#xA;优化的目标是提高查询效率，可能包括：&lt;br&gt;&#xA;选择适当的索引：根据数据分布和查询条件选择最合适的索引。&lt;br&gt;&#xA;连接顺序优化：对于多表连接，优化器会根据表的大小、索引等选择合适的连接顺序。&lt;br&gt;&#xA;子查询优化：优化器可能将子查询重写为连接或其他形式以提高效率。&lt;br&gt;&#xA;优化完成后，优化器会将逻辑算子转换为物理算子，物理算子负责执行具体的操作（如表扫描、索引查找等）。&lt;/p&gt;&#xA;&lt;h1 id=&#34;3-中间传递&#34;&gt;3. 中间传递&lt;/h1&gt;&#xA;&lt;p&gt;&lt;code&gt;SQLStageEvent&lt;/code&gt;类用于在SQL语句的不同阶段传递信息。在MiniOB项目的执行流程中,SQL语句的处理过程可以通过&lt;code&gt;SQLStageEvent&lt;/code&gt;类将SQL相关的数据结构（如 &lt;code&gt;ParsedSqlNode&lt;/code&gt;、&lt;code&gt;Stmt&lt;/code&gt;、&lt;code&gt;PhysicalOperator&lt;/code&gt;）在不同阶段之间传递。&lt;/p&gt;&#xA;&lt;h2 id=&#34;31-示例&#34;&gt;3.1 示例&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;解析阶段：&lt;code&gt;ParsedSqlNode&lt;/code&gt; 被创建并设置为 &lt;code&gt;sql_node_&lt;/code&gt;。&lt;/li&gt;&#xA;&lt;li&gt;语义分析阶段：将 &lt;code&gt;ParsedSqlNode&lt;/code&gt; 转换为 &lt;code&gt;Stmt&lt;/code&gt; 对象，并设置到 &lt;code&gt;stmt_&lt;/code&gt; 中。&lt;/li&gt;&#xA;&lt;li&gt;执行计划生成阶段：基于 &lt;code&gt;Stmt&lt;/code&gt; 生成 &lt;code&gt;PhysicalOperator&lt;/code&gt;，并设置到 &lt;code&gt;operator_&lt;/code&gt; 中。&lt;/li&gt;&#xA;&lt;li&gt;执行阶段：执行器通过 &lt;code&gt;PhysicalOperator&lt;/code&gt; 来访问存储层，执行SQL语句。&lt;/li&gt;&#xA;&lt;/ol&gt;</description>
    </item>
    <item>
      <title></title>
      <link>http://localhost:1313/posts/nginx-%E5%86%85%E5%AD%98%E6%B1%A0/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/nginx-%E5%86%85%E5%AD%98%E6%B1%A0/</guid>
      <description>&lt;p&gt;点击返回&lt;a href=&#34;https://2549141519.github.io/#/toc&#34;&gt;🔗我的博客文章目录&lt;/a&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;目录&#xA;{:toc}&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;!-- raw HTML omitted --&gt;&#xA;&lt;h1 id=&#34;1-介绍&#34;&gt;1. 介绍&lt;/h1&gt;&#xA;&lt;p&gt;Nginx 内存池的实现是其高性能、高并发处理能力的重要组成部分之一。Nginx 的内存池主要用于高效管理内存，避免频繁的内存分配与释放操作，减少内存碎片，提升性能。Nginx 内存池的实现遵循“预分配一块内存，然后进行小块分配”的策略，类似于常见的内存池模型。&lt;br&gt;&#xA;Nginx在 &lt;a href=&#34;https://github.com/nginx/nginx/blob/master/src/core/ngx_palloc.h&#34;&gt;ngx_palloc.h&lt;/a&gt; 和 &lt;a href=&#34;https://github.com/nginx/nginx/blob/master/src/core/ngx_palloc.c&#34;&gt;ngx_palloc.c&lt;/a&gt; 中实现了内存池。&lt;/p&gt;&#xA;&lt;h1 id=&#34;2-内存池的实现原理&#34;&gt;2. 内存池的实现原理&lt;/h1&gt;&#xA;&lt;h2 id=&#34;21-nginx-内存池的结构&#34;&gt;2.1 Nginx 内存池的结构&lt;/h2&gt;&#xA;&lt;p&gt;&lt;code&gt;ngx_pool_s&lt;/code&gt; 结构体是内存池的核心结构，它管理内存块的链表、内存池的大小信息、以及清理函数等。其定义如下：&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;struct ngx_pool_s {&#xA;    ngx_pool_data_t       d;         // 内存块的数据&#xA;    size_t                max;       // 可从该内存池分配的最大内存块大小&#xA;    ngx_pool_t           *current;   // 当前活跃的内存块&#xA;    ngx_chain_t          *chain;     // 缓存链&#xA;    ngx_pool_large_t     *large;     // 大块内存链表&#xA;    ngx_pool_cleanup_t   *cleanup;   // 清理函数链表&#xA;    ngx_log_t            *log;       // 日志对象&#xA;};&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;其中，ngx_pool_data_t 定义了每个内存块的元数据：&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;typedef struct {&#xA;    u_char      *last;    // 当前内存块中已使用的最后位置&#xA;    u_char      *end;     // 当前内存块的末尾位置&#xA;    ngx_pool_t  *next;    // 下一个内存块的指针&#xA;    ngx_uint_t   failed;  // 分配失败次数&#xA;} ngx_pool_data_t;&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;22-内存池的创建和销毁&#34;&gt;2.2 内存池的创建和销毁&lt;/h2&gt;&#xA;&lt;p&gt;&lt;code&gt;ngx_create_pool&lt;/code&gt;函数用于创建一个内存池，分配一个初始大小为 size 的内存块，并初始化内存池的各种参数：&lt;/p&gt;</description>
    </item>
    <item>
      <title></title>
      <link>http://localhost:1313/posts/paxos-%E5%88%86%E5%B8%83%E5%BC%8F%E5%85%B1%E8%AF%86%E7%AE%97%E6%B3%95/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/paxos-%E5%88%86%E5%B8%83%E5%BC%8F%E5%85%B1%E8%AF%86%E7%AE%97%E6%B3%95/</guid>
      <description>&lt;p&gt;点击返回&lt;a href=&#34;https://2549141519.github.io/#/toc&#34;&gt;🔗我的博客文章目录&lt;/a&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;目录&#xA;{:toc}&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;!-- raw HTML omitted --&gt;&#xA;&lt;p&gt;paper &lt;a href=&#34;https://www.microsoft.com/en-us/research/uploads/prod/2016/12/paxos-simple-Copy.pdf&#34;&gt;link&lt;/a&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;1-paxos算法介绍&#34;&gt;1. Paxos算法介绍&lt;/h1&gt;&#xA;&lt;p&gt;Paxos 是一种用于 分布式系统 中达成一致性的算法，通常用于解决分布式系统中的 共识问题。它保证了即使在系统中的某些节点出现故障时，多个节点也能就某个值或状态达成一致。Paxos 主要用于在没有中央协调者的系统中确保数据的 一致性 和 可靠性。&lt;/p&gt;&#xA;&lt;p&gt;Paxos的工作流程可以分为三个主要角色和三个阶段。&lt;/p&gt;&#xA;&lt;h2 id=&#34;11-三个主要角色&#34;&gt;1.1 三个主要角色&lt;/h2&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;1. Proposer：提议者，负责生成提议值，并发送提议消息给Acceptor，建议某个值成为共识值。  &#xA;2. Acceptor：接受者，负责接收和存储提议。多数 Acceptor 接受提议后，该提议才能生效。  &#xA;3. Learner：学习者，负责接收Acceptor的响应，学习最终达成的共识结果。  &#xA;&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;12-三个阶段&#34;&gt;1.2 三个阶段&lt;/h2&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;1. Prepare 阶段：&#xA;提议者向接受者发送提议，要求 Acceptor 表示是否愿意接受更高编号的提议。&#xA;2. Promise 阶段：&#xA;Acceptor 向 Proposer 承诺不会接受编号低于当前提议的其他提议。&#xA;3. Accept 阶段：&#xA;一旦提议获得大多数 Acceptor 的同意，Proposer 就可以宣布该提议通过，Learner 将会学习到最终的共识值。&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;13-paxos的关键特性&#34;&gt;1.3 Paxos的关键特性&lt;/h2&gt;&#xA;&lt;p&gt;容错性：&lt;br&gt;&#xA;即使部分节点故障（如网络分区或节点崩溃），Paxos 仍然可以正常工作，只要大多数节点（一般为超过半数的 Acceptor）正常工作。&lt;/p&gt;&#xA;&lt;p&gt;一致性：&lt;br&gt;&#xA;所有节点最终都会达成一致的共识值，保证系统不会出现不同步的情况。&lt;/p&gt;&#xA;&lt;p&gt;可恢复性：&lt;br&gt;&#xA;即使系统发生故障，恢复后 Paxos 仍能继续从上次中断的地方继续运行，不会丢失已经达成的共识。&lt;/p&gt;&#xA;&lt;h1 id=&#34;2-一致性算法&#34;&gt;2. 一致性算法&lt;/h1&gt;&#xA;&lt;p&gt;一致性算法是Paxos的核心。目的是在多个进程中达成一致选择某个值（即 共识），并提出了实现这种共识的 安全性要求。&lt;/p&gt;&#xA;&lt;h2 id=&#34;21-共识问题的基本目标&#34;&gt;2.1 共识问题的基本目标&lt;/h2&gt;&#xA;&lt;p&gt;共识算法的目标是确保在一组提议的值中，选择一个并让系统内的所有进程知道这个被选择的值。具体要求包括：&lt;/p&gt;</description>
    </item>
    <item>
      <title></title>
      <link>http://localhost:1313/posts/pre-push%E6%9C%AC%E5%9C%B0%E9%9B%86%E6%88%90%E6%B5%8B%E8%AF%95/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/pre-push%E6%9C%AC%E5%9C%B0%E9%9B%86%E6%88%90%E6%B5%8B%E8%AF%95/</guid>
      <description>&lt;p&gt;点击返回&lt;a href=&#34;https://2549141519.github.io/#/toc&#34;&gt;🔗我的博客文章目录&lt;/a&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;目录&#xA;{:toc}&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;!-- raw HTML omitted --&gt;&#xA;&lt;h1 id=&#34;1-集成测试&#34;&gt;1. 集成测试&lt;/h1&gt;&#xA;&lt;p&gt;集成测试（Integration Testing）是一种软件测试方法，旨在验证不同模块或组件之间的交互是否按预期工作。集成测试关注多个模块或组件的组合和它们之间的接口。&lt;/p&gt;&#xA;&lt;h1 id=&#34;2-本地集成测试&#34;&gt;2. 本地集成测试&lt;/h1&gt;&#xA;&lt;p&gt;修改github项目并提交（git push）时，会触发pre-push钩子，在pre-push钩子中，会执行集成测试，并判断是否通过。&#xA;本文编写了简单的集成测试，在项目提交时，集成测试会判断是否编译成功（c++），若不成功则提示编译失败，并阻止提交。&#xA;未修改pre-push钩子时，默认将不会执行集成测试：&lt;br&gt;&#xA;&lt;img src=&#34;../blogImg/IntegrationTesting2.PNG&#34; alt=&#34;Alt text&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;3-pre-push集成测试的实现&#34;&gt;3. pre-push集成测试的实现&lt;/h1&gt;&#xA;&lt;h2 id=&#34;31-编写c文件用于测试集成测试是否成功&#34;&gt;3.1 编写c++文件，用于测试集成测试是否成功&lt;/h2&gt;&#xA;&lt;p&gt;代码如下：&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;#include &lt;!-- raw HTML omitted --&gt;&lt;br&gt;&#xA;int main() {&lt;br&gt;&#xA;int n = 0;&lt;br&gt;&#xA;std::cout &amp;laquo; n &amp;laquo; std::endl;&lt;br&gt;&#xA;return 0;&lt;br&gt;&#xA;}&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;h2 id=&#34;32-编写pre-push钩子脚本用于执行编译测试&#34;&gt;3.2 编写pre-push钩子脚本，用于执行编译测试&lt;/h2&gt;&#xA;&lt;p&gt;&lt;img src=&#34;../blogImg/IntegrationTesting4.PNG&#34; alt=&#34;Alt text&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;在项目根目录的.git/hooks中新建pre-push文件:&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;remote=&amp;#34;$1&amp;#34;&#xA;url=&amp;#34;$2&amp;#34;&#xA;# Step 1: 编译 C++ 代码&#xA;echo &amp;#34;Compiling C++ code...&amp;#34;&#xA;g++ -o main main.cpp&#xA;if [ $? -ne 0 ]; then&#xA;    echo &amp;#34;Compilation failed. Aborting push.&amp;#34;&#xA;    exit 1&#xA;fi&#xA;echo &amp;#34;Compilation succeeded. Proceeding to check commits...&amp;#34;&#xA;# Step 2: 检查提交信息中是否包含 &amp;#34;WIP&amp;#34;&#xA;# 计算空内容的哈希值（用于检查是否是删除操作）&#xA;zero=$(git hash-object --stdin &amp;lt;/dev/null | tr &amp;#39;[0-9a-f]&amp;#39; &amp;#39;0&amp;#39;)&#xA;# 读取 git push 提供的本地和远程引用&#xA;while read local_ref local_oid remote_ref remote_oid&#xA;do&#xA;        if test &amp;#34;$local_oid&amp;#34; = &amp;#34;$zero&amp;#34;&#xA;        then&#xA;                # Handle delete&#xA;                :&#xA;        else&#xA;                if test &amp;#34;$remote_oid&amp;#34; = &amp;#34;$zero&amp;#34;&#xA;                then&#xA;                        # New branch, examine all commits&#xA;                        range=&amp;#34;$local_oid&amp;#34;&#xA;                else&#xA;                        # Update to existing branch, examine new commits&#xA;                        range=&amp;#34;$remote_oid..$local_oid&amp;#34;&#xA;                fi&#xA;                # Check for WIP commit&#xA;                commit=$(git rev-list -n 1 --grep &amp;#39;^WIP&amp;#39; &amp;#34;$range&amp;#34;)&#xA;                if test -n &amp;#34;$commit&amp;#34;&#xA;                then&#xA;                        echo &amp;gt;&amp;amp;2 &amp;#34;Found WIP commit in $local_ref, not pushing&amp;#34;&#xA;                        exit 1&#xA;                fi&#xA;        fi&#xA;done&#xA;exit 0&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;编写完成后执行命令&lt;code&gt;chmod +x pre-push&lt;/code&gt;，使文件具有可执行权限。&lt;/p&gt;</description>
    </item>
    <item>
      <title></title>
      <link>http://localhost:1313/posts/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/</guid>
      <description>&lt;p&gt;点击返回&lt;a href=&#34;https://2549141519.github.io/#/toc&#34;&gt;🔗我的博客文章目录&lt;/a&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;目录&#xA;{:toc}&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;!-- raw HTML omitted --&gt;&#xA;&lt;h1 id=&#34;1-虚拟内存&#34;&gt;1. 虚拟内存&lt;/h1&gt;&#xA;&lt;p&gt;硬件支持：&lt;br&gt;&#xA;现代处理器通过内存管理单元（MMU）支持虚拟内存。虚拟内存将物理内存和存储设备（如硬盘）结合起来，使操作系统和程序可以使用比物理内存更多的空间。处理器中的MMU负责将进程访问的虚拟地址转换为物理地址。&lt;/p&gt;&#xA;&lt;p&gt;操作系统机制：&lt;br&gt;&#xA;操作系统通过页表（Page Table）来维护虚拟地址和物理地址的映射关系。当进程请求的虚拟内存页不在物理内存中时，操作系统会产生“缺页中断”（Page Fault），然后从硬盘中加载相应的页面。&lt;/p&gt;&#xA;&lt;h1 id=&#34;2-内存管理单元mmu&#34;&gt;2. 内存管理单元（MMU）&lt;/h1&gt;&#xA;&lt;p&gt;MMU是计算机处理器中的一个硬件模块，它负责虚拟地址到物理地址的转换。在访问内存时，CPU首先生成虚拟地址，MMU将其转换为物理地址，从而访问实际的物理内存。&lt;/p&gt;&#xA;&lt;p&gt;TLB（Translation Lookaside Buffer）：&lt;br&gt;&#xA;MMU中还有一种缓存叫TLB，用来存储虚拟地址到物理地址的映射，避免每次访问内存都进行复杂的页表查找。&lt;/p&gt;&#xA;&lt;h1 id=&#34;3-内存共享&#34;&gt;3. 内存共享&lt;/h1&gt;&#xA;&lt;p&gt;多个进程可以通过操作系统提供的共享内存机制共享物理内存的同一部分。共享内存是一种高效的进程间通信方式，避免了数据复制。&lt;/p&gt;&#xA;&lt;p&gt;操作系统支持：&lt;br&gt;&#xA;共享内存通常由操作系统提供的系统调用（如&lt;code&gt;shmget&lt;/code&gt;和&lt;code&gt;shmat&lt;/code&gt;）实现。操作系统允许多个进程通过映射同一段物理内存来共享数据。&lt;/p&gt;&#xA;&lt;h1 id=&#34;4-堆和栈的内存管理&#34;&gt;4. 堆和栈的内存管理&lt;/h1&gt;&#xA;&lt;p&gt;栈（Stack）：&lt;br&gt;&#xA;栈是一种连续的内存区域，常用于存储函数的局部变量和调用信息。栈的内存分配是自动的，当函数调用结束时，栈内存会自动释放。栈空间相对较小，速度快，但存储量有限。&lt;/p&gt;&#xA;&lt;p&gt;堆（Heap）：&lt;br&gt;&#xA;堆用于动态分配内存，程序需要显式分配和释放堆内存（如C语言中的&lt;code&gt;malloc&lt;/code&gt;和&lt;code&gt;free&lt;/code&gt;）。堆的内存可以不连续，且大小比栈大得多。&lt;/p&gt;&#xA;&lt;h1 id=&#34;5-缓存管理&#34;&gt;5. 缓存管理&lt;/h1&gt;&#xA;&lt;p&gt;硬件缓存：&lt;br&gt;&#xA;处理器内部通常有多级缓存（L1、L2、L3），这些缓存用于存储最近访问的内存数据，减少访问主内存的延迟。&lt;/p&gt;&#xA;&lt;p&gt;软件缓存：&lt;br&gt;&#xA;数据库在应用层面也会实现缓存，例如缓冲池（Buffer Pool），用于缓存磁盘中的数据页，减少磁盘I/O操作。&lt;/p&gt;&#xA;&lt;h1 id=&#34;6-垃圾回收garbage-collection&#34;&gt;6. 垃圾回收（Garbage Collection）&lt;/h1&gt;&#xA;&lt;p&gt;手动内存管理：&lt;br&gt;&#xA;在C/C++中，开发者需要手动管理内存的分配和释放，未能正确释放内存会导致内存泄漏。&lt;/p&gt;&#xA;&lt;p&gt;自动垃圾回收：&lt;br&gt;&#xA;如Java等语言中有自动垃圾回收（GC）机制，GC通过追踪哪些内存块不再被引用来自动回收内存。&lt;/p&gt;&#xA;&lt;h1 id=&#34;7-内存对齐&#34;&gt;7. 内存对齐&lt;/h1&gt;&#xA;&lt;p&gt;CPU访问内存时，通常要求数据按特定字节对齐。例如，32位系统中，4字节的整数应按4字节对齐，64位系统中，8字节的数据应按8字节对齐。&lt;/p&gt;&#xA;&lt;p&gt;对齐内存访问可以提高访问速度，因为未对齐的访问可能需要多次内存访问。&lt;/p&gt;&#xA;&lt;h1 id=&#34;8-内存映射io&#34;&gt;8. 内存映射I/O&lt;/h1&gt;&#xA;&lt;p&gt;内存映射I/O（Memory-mapped I/O）允许将外部设备（如磁盘）直接映射到进程的地址空间中，从而可以通过内存读写操作访问设备。&lt;/p&gt;&#xA;&lt;p&gt;操作系统提供系统调用（如&lt;code&gt;mmap&lt;/code&gt;），允许将文件或设备映射到内存中，这样文件中的数据就可以像内存一样访问。&lt;/p&gt;&#xA;&lt;h1 id=&#34;9-内存碎片化&#34;&gt;9. 内存碎片化&lt;/h1&gt;&#xA;&lt;p&gt;内存碎片：&lt;br&gt;&#xA;随着内存的频繁分配和释放，可能会产生内存碎片。外部碎片是未被使用的小块内存，而内部碎片则是已分配但未完全使用的内存。&lt;/p&gt;&#xA;&lt;p&gt;内存管理技术：&lt;br&gt;&#xA;通过内存池、紧凑分配等技术，可以减少内存碎片，提高内存使用效率。&lt;/p&gt;&#xA;&lt;h1 id=&#34;10-数据库中特定的内存管理技术&#34;&gt;10. 数据库中特定的内存管理技术&lt;/h1&gt;&#xA;&lt;p&gt;MVCC（多版本并发控制）：&lt;br&gt;&#xA;MVCC通过存储数据的多个版本来支持并发事务。数据库需要管理不同版本的内存数据，确保旧版本能及时清理，避免内存浪费。&lt;/p&gt;&#xA;&lt;p&gt;日志管理：&lt;br&gt;&#xA;数据库使用Redo Log和Undo Log来管理事务的回滚和恢复，这些日志需要有效的内存管理来确保高效性。&lt;/p&gt;</description>
    </item>
    <item>
      <title></title>
      <link>http://localhost:1313/posts/%E5%A4%A7%E8%A7%84%E6%A8%A1%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86-mapreduce%E5%A4%84%E7%90%86tb%E7%BA%A7%E7%94%9A%E8%87%B3pb%E7%BA%A7%E6%95%B0%E6%8D%AE/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/%E5%A4%A7%E8%A7%84%E6%A8%A1%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86-mapreduce%E5%A4%84%E7%90%86tb%E7%BA%A7%E7%94%9A%E8%87%B3pb%E7%BA%A7%E6%95%B0%E6%8D%AE/</guid>
      <description>&lt;p&gt;点击返回&lt;a href=&#34;https://2549141519.github.io/#/toc&#34;&gt;🔗我的博客文章目录&lt;/a&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;目录&#xA;{:toc}&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;!-- raw HTML omitted --&gt;&#xA;&lt;p&gt;大规模数据处理是指对海量数据进行采集、存储、分析和可视化的过程。在此列出常见的大规模数据处理方式，最后探讨MapReduce处理海量数据。&lt;/p&gt;&#xA;&lt;h1 id=&#34;1-批处理-batch-processing&#34;&gt;1. 批处理 (Batch Processing)&lt;/h1&gt;&#xA;&lt;p&gt;批处理是一种传统的数据处理方法，适用于需要处理大量数据但不要求实时响应的场景。&lt;/p&gt;&#xA;&lt;p&gt;典型技术/框架：Hadoop MapReduce、Apache Spark（批处理模式）。&lt;/p&gt;&#xA;&lt;p&gt;特点：&#xA;处理的数据量很大，通常是以整个数据集为单位进行操作。&#xA;适用于定期处理，如每日或每周的报表生成。&#xA;延迟高，因为必须等待所有数据收集齐全后再开始处理。&lt;/p&gt;&#xA;&lt;p&gt;应用场景：&#xA;日志处理与分析（如日志汇总和错误报告）。&#xA;数据仓库构建和ETL（提取、转换、加载）过程。&lt;/p&gt;&#xA;&lt;h1 id=&#34;2-流处理-stream-processing&#34;&gt;2. 流处理 (Stream Processing)&lt;/h1&gt;&#xA;&lt;p&gt;流处理（也称为实时处理）用于在数据到达系统时立即处理数据，以支持实时分析和响应。&lt;/p&gt;&#xA;&lt;p&gt;典型技术/框架：Apache Kafka、Apache Flink、Apache Storm、Apache Spark（流处理模式）、Google Cloud Dataflow。&lt;/p&gt;&#xA;&lt;p&gt;特点：&#xA;数据是连续到达的，处理是增量的。&#xA;低延迟，适用于实时数据处理需求。&#xA;处理时不会等待所有数据集齐，而是处理每一个到达的数据记录。&lt;/p&gt;&#xA;&lt;p&gt;应用场景：&#xA;实时监控（如金融交易监控、网络安全检测）。&#xA;实时推荐系统（如电商实时推荐、社交媒体趋势分析）。&lt;/p&gt;&#xA;&lt;h1 id=&#34;3-分布式计算-distributed-computing&#34;&gt;3. 分布式计算 (Distributed Computing)&lt;/h1&gt;&#xA;&lt;p&gt;分布式计算通过将数据和计算任务分散到多个机器或节点上，从而并行处理数据。通常用于大规模数据处理场景。&lt;/p&gt;&#xA;&lt;p&gt;典型技术/框架：Apache Hadoop、Apache Spark、Dask、Ray。&lt;/p&gt;&#xA;&lt;p&gt;特点：&#xA;处理数据时，数据被划分为多个分片并在不同的节点上并行处理。&#xA;具备良好的扩展性和容错性。&#xA;适用于需要复杂计算和分析的大数据集。&lt;/p&gt;&#xA;&lt;p&gt;应用场景：&#xA;数据分析和机器学习任务。&#xA;大规模图计算和复杂查询（如社交网络分析、基因组数据分析）。&lt;/p&gt;&#xA;&lt;h1 id=&#34;4-并行处理-parallel-processing&#34;&gt;4. 并行处理 (Parallel Processing)&lt;/h1&gt;&#xA;&lt;p&gt;并行处理是通过多个处理器同时执行多个计算任务的方式来加速数据处理。与分布式计算不同，并行处理通常在同一个计算机或多核处理器上进行。&lt;/p&gt;&#xA;&lt;p&gt;典型技术/框架：多线程编程、OpenMP、MPI、CUDA（用于GPU加速）。&lt;/p&gt;&#xA;&lt;p&gt;特点：&#xA;数据和计算被分解为多个任务，分配到多个处理器/核进行并行计算。&#xA;适用于需要高性能计算的任务。&#xA;在共享内存架构上表现良好。&lt;/p&gt;&#xA;&lt;p&gt;应用场景：&#xA;科学计算（如气象预测、物理模拟）。&#xA;图像处理和视频编码。&lt;/p&gt;</description>
    </item>
    <item>
      <title></title>
      <link>http://localhost:1313/posts/%E6%9C%8D%E5%8A%A1%E5%99%A8&#43;csv%E5%AE%89%E8%A3%85/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/%E6%9C%8D%E5%8A%A1%E5%99%A8&#43;csv%E5%AE%89%E8%A3%85/</guid>
      <description>&lt;p&gt;点击返回&lt;a href=&#34;https://2549141519.github.io/#/toc&#34;&gt;🔗我的博客文章目录&lt;/a&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;目录&#xA;{:toc}&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;!-- raw HTML omitted --&gt;&#xA;&lt;h1 id=&#34;ubuntu装服务器&#34;&gt;Ubuntu装服务器&lt;/h1&gt;&#xA;&lt;h3 id=&#34;下载&#34;&gt;下载&lt;/h3&gt;&#xA;&lt;p&gt;去Ubuntu官网找到20.04的镜像文件，下载 iso文件(server版本 放入u盘)&lt;/p&gt;&#xA;&lt;h3 id=&#34;安装&#34;&gt;安装&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;使用新创建的可引导USB驱动器引导系统 按住F12键 选择英文&#xA;&lt;img src=&#34;../blogImg/%E6%9C%8D%E5%8A%A1%E5%99%A8+csv1.png&#34; alt=&#34;![Alt text](image.png)&#34;&gt;&lt;/li&gt;&#xA;&lt;li&gt;键盘布局选择默认&#xA;&lt;img src=&#34;../blogImg/%E6%9C%8D%E5%8A%A1%E5%99%A8+csv2.png&#34; alt=&#34;![Alt text](image.png)&#34;&gt;&lt;/li&gt;&#xA;&lt;li&gt;手动填入IP地址&#xA;&lt;img src=&#34;../blogImg/%E6%9C%8D%E5%8A%A1%E5%99%A8+csv3.png&#34; alt=&#34;![Alt text](image.png)&#34;&gt;&lt;/li&gt;&#xA;&lt;li&gt;代理不填 默认 接下来都选择默认 到用户名阶段 创建用户密码&#xA;&lt;img src=&#34;../blogImg/%E6%9C%8D%E5%8A%A1%E5%99%A8+csv4.png&#34; alt=&#34;![Alt text](image.png)&#34;&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h3 id=&#34;网络配置&#34;&gt;网络配置&lt;/h3&gt;&#xA;&lt;p&gt;装好之后 配置网络&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;$ sudo vi /etc/netplan/00-installer-config.yaml&#xA;// 编辑如下，把其他网卡删掉了&#xA;// 配置信息需要根据实际情况修改&#xA;# This is the network config written by &amp;#39;subiquity&amp;#39;&#xA;network:&#xA;  ethernets:&#xA;    eno3:&#xA;      dhcp4: no&#xA;      dhcp6: no&#xA;      addresses: [your.ip/24]&#xA;      gateway4: your.gateway&#xA;      nameservers:&#xA;        addresses: [your.dns1, your.dns2]&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;配置生效 &lt;code&gt;sudo netplan apply&lt;/code&gt;&lt;/p&gt;&#xA;&lt;h3 id=&#34;替换镜像源-能apt-install&#34;&gt;替换镜像源 能apt-install&lt;/h3&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;sudo cp /etc/apt/source.list /etc/apt/source.list.origin&#xA;sudo vi /etc/apt/source.list&#xA;deb http://mirrors.aliyun.com/ubuntu/ focal main restricted universe multiverse&#xA;deb http://mirrors.aliyun.com/ubuntu/ focal-security main restricted universe multiverse&#xA;deb http://mirrors.aliyun.com/ubuntu/ focal-updates main restricted universe multiverse&#xA;deb http://mirrors.aliyun.com/ubuntu/ focal-backports main restricted universe multiverse&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;安装梯子&#34;&gt;安装梯子&lt;/h3&gt;&#xA;&lt;p&gt;这个我就不写了 有需要可由我来装&lt;/p&gt;</description>
    </item>
    <item>
      <title></title>
      <link>http://localhost:1313/posts/%E7%BA%BF%E4%B8%8A%E9%9B%86%E6%88%90%E6%B5%8B%E8%AF%95/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/%E7%BA%BF%E4%B8%8A%E9%9B%86%E6%88%90%E6%B5%8B%E8%AF%95/</guid>
      <description>&lt;p&gt;点击返回&lt;a href=&#34;https://2549141519.github.io/#/toc&#34;&gt;🔗我的博客文章目录&lt;/a&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;目录&#xA;{:toc}&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;!-- raw HTML omitted --&gt;&#xA;&lt;h1 id=&#34;1-github-actions的工作流文件&#34;&gt;1. GitHub Actions的工作流文件&lt;/h1&gt;&#xA;&lt;p&gt;.github/workflows 文件夹中的每个文件都是一个工作流（workflow），通常以.yml或.yaml结尾。&lt;br&gt;&#xA;每个工作流文件定义了一组自动化任务，这些任务会在特定事件发生时（如代码推送、PR创建、计划任务等）触发执行。&lt;br&gt;&#xA;工作流的组成：&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;name: 工作流的名称，用于标识这个工作流。&lt;br&gt;&#xA;on: 触发工作流的事件（如push、pull_request、schedule等）。&lt;br&gt;&#xA;jobs: 一组任务，每个任务可以在不同的虚拟机环境中运行。任务可以包含多个步骤（steps），每个步骤是一个具体的Shell命令或GitHub Action。&lt;br&gt;&#xA;steps: 每个job下的具体步骤，用于执行脚本、运行命令、调用外部的GitHub Action等。&lt;/p&gt;&#xA;&lt;h1 id=&#34;2-workflows集成测试实现&#34;&gt;2. workflows集成测试实现&lt;/h1&gt;&#xA;&lt;p&gt;要求集成测试能测试项目是否成功编译。&lt;br&gt;&#xA;在3TS中，有两种编译方式：&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;直接编译安装，在&lt;code&gt;3TS/src/dbtest&lt;/code&gt;目录下执行&lt;br&gt;&#xA;&lt;code&gt;cmake -S ./&lt;/code&gt;&lt;br&gt;&#xA;&lt;code&gt;make&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;使用docker编译，执行以下命令安装docker（如果还未安装docker）&lt;br&gt;&#xA;&lt;code&gt;curl -s https://get.docker.com/ | sh&lt;/code&gt;&lt;br&gt;&#xA;获取镜像&lt;br&gt;&#xA;&lt;code&gt;docker pull registry.cn-hangzhou.aliyuncs.com/open_projects/3ts_coo:1.0&lt;/code&gt;&lt;br&gt;&#xA;查看镜像ID，并根据镜像ID生成容器&lt;br&gt;&#xA;&lt;code&gt;docker images&lt;/code&gt;&lt;br&gt;&#xA;&lt;code&gt;docker run -it [image_id] /bin/bash&lt;/code&gt;&lt;br&gt;&#xA;查看所有容器，进入容器&lt;br&gt;&#xA;&lt;code&gt;docker ps -a&lt;/code&gt;&lt;br&gt;&#xA;&lt;code&gt;docker exec -it [container_id] /bin/bash&lt;/code&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;21-集成测试实现&#34;&gt;2.1 集成测试实现&lt;/h2&gt;&#xA;&lt;p&gt;在项目根目录下，进入&lt;code&gt;.github/workflows&lt;/code&gt;文件夹，新建&lt;code&gt;ci.yml&lt;/code&gt;文件，添加如下内容：&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;name: 3TS CI&#xA;&#xA;on:&#xA;  push:&#xA;    branches:&#xA;      - coo-consistency-check&#xA;  pull_request:&#xA;    branches:&#xA;      - coo-consistency-check&#xA;&#xA;jobs:&#xA;  build_and_test:&#xA;    runs-on: ubuntu-latest&#xA;&#xA;    steps:&#xA;    - uses: actions/checkout@v2&#xA;&#xA;    # 设置构建环境和安装依赖项&#xA;    - name: Set up build environment&#xA;      run: |&#xA;        echo &amp;#34;Setting up build environment...&amp;#34;&#xA;        sudo apt-get update &amp;amp;&amp;amp; sudo apt-get install -y cmake make g++ libgflags-dev unixodbc unixodbc-dev odbcinst odbcinst1debian2&#xA;        echo &amp;#34;Build environment setup complete.&amp;#34;&#xA;&#xA;    # 安装 Docker，如果尚未安装&#xA;    - name: Install Docker&#xA;      run: |&#xA;        echo &amp;#34;Installing Docker...&amp;#34;&#xA;        curl -s https://get.docker.com/ | sh&#xA;        echo &amp;#34;Docker installed successfully.&amp;#34;&#xA;&#xA;    # 拉取 Docker 镜像&#xA;    - name: Pull Docker image&#xA;      run: docker pull registry.cn-hangzhou.aliyuncs.com/open_projects/3ts_coo:1.0&#xA;&#xA;    # 列出 Docker 镜像&#xA;    - name: List Docker images&#xA;      run: docker images&#xA;&#xA;    # 运行 Docker 容器，并挂载项目目录&#xA;    - name: Run Docker container with volume&#xA;      run: |&#xA;        IMAGE_ID=$(docker images -q registry.cn-hangzhou.aliyuncs.com/open_projects/3ts_coo:1.0)&#xA;        docker run -d --name 3ts_container -v ${{ github.workspace }}:/src $IMAGE_ID tail -f /dev/null&#xA;&#xA;    # 在 Docker 容器中编译&#xA;    - name: Compile inside Docker&#xA;      run: |&#xA;        echo &amp;#34;Compiling in Docker container...&amp;#34;&#xA;        docker exec -i 3ts_container bash -c &amp;#34;cd /src/src/dbtest &amp;amp;&amp;amp; cmake -S ./ &amp;amp;&amp;amp; make&amp;#34;&#xA;&#xA;    # 清理 Docker 容器&#xA;    - name: Clean up Docker container&#xA;      if: always()&#xA;      run: docker rm -f 3ts_container&#xA;&#xA;    # 在非 Docker 环境编译&#xA;    - name: Compile without Docker&#xA;      run: |&#xA;        echo &amp;#34;Compiling using CMake...&amp;#34;&#xA;        cd src/dbtest&#xA;        sudo rm -rf CMakeCache.txt CMakeFiles  # 清除缓存文件&#xA;        cmake -S ./ || cmake -DCMAKE_PREFIX_PATH=/usr/ -S ./&#xA;        make&#xA;        echo &amp;#34;Compilation finished.&amp;#34;&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;提交代码到&lt;code&gt;coo-consistency-check&lt;/code&gt;分支，GitHub Actions就会自动触发工作流，并执行测试。申请pull request，审核通过也可以触发工作流。&lt;br&gt;&#xA;测试通过，说明项目可以成功编译。&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
