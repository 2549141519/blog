<!DOCTYPE html>
<html lang="en-us">
  <head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    
    <title>Wei Haoyu</title>
    <meta name="viewport" content="width=device-width,minimum-scale=1">
    <meta name="description" content="点击返回🔗我的博客文章目录

目录
{:toc}


paper link
1.介绍
MapReduce 是一种用于处理和生成大规模数据集的编程模型。它将数据处理分为两个主要阶段：Map 和 Reduce，从而实现对大数据的并行计算和分布式处理。MapReduce的设计目标是能够在计算机集群上高效处理TB级甚至PB级的数据集。
2.编程模型
例如大型文档集合中每个单词出现次数的问题，我们可以使用MapReduce处理，下文将默认处理该问题。
2.1Example
伪代码：

map(String key, String value):
// key: document name
// value: document contents
for each word w in value:
EmitIntermediate(w, &ldquo;1&rdquo;);
reduce(String key, Iterator values):
// key: a word
// values: a list of counts
int result = 0;
for each v in values:
result &#43;= ParseInt(v);
Emit(AsString(result));
map函数发出每个单词加上一个相关的出现次数计数(在这个简单的示例中只有&rsquo; 1 &lsquo;)。reduce函数将针对特定单词发出的所有计数求和。
mapTask函数具体实现：">
    <meta name="generator" content="Hugo 0.145.0">
    
    
    
      <meta name="robots" content="noindex, nofollow">
    
    

    
<link rel="stylesheet" href="/ananke/css/main.min.css" >




    


    
      

    

    

    
      <link rel="canonical" href="http://localhost:1313/posts/mapreduce/">
    

    <meta property="og:url" content="http://localhost:1313/posts/mapreduce/">
  <meta property="og:site_name" content="Wei Haoyu">
  <meta property="og:title" content="Wei Haoyu">
  <meta property="og:description" content="点击返回🔗我的博客文章目录
目录 {:toc} paper link
1.介绍 MapReduce 是一种用于处理和生成大规模数据集的编程模型。它将数据处理分为两个主要阶段：Map 和 Reduce，从而实现对大数据的并行计算和分布式处理。MapReduce的设计目标是能够在计算机集群上高效处理TB级甚至PB级的数据集。
2.编程模型 例如大型文档集合中每个单词出现次数的问题，我们可以使用MapReduce处理，下文将默认处理该问题。
2.1Example 伪代码：
map(String key, String value):
// key: document name
// value: document contents
for each word w in value:
EmitIntermediate(w, “1”);
reduce(String key, Iterator values):
// key: a word
// values: a list of counts
int result = 0;
for each v in values:
result &#43;= ParseInt(v);
Emit(AsString(result));
map函数发出每个单词加上一个相关的出现次数计数(在这个简单的示例中只有’ 1 ‘)。reduce函数将针对特定单词发出的所有计数求和。 mapTask函数具体实现：">
  <meta property="og:locale" content="en_us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">

  <meta itemprop="name" content="Wei Haoyu">
  <meta itemprop="description" content="点击返回🔗我的博客文章目录
目录 {:toc} paper link
1.介绍 MapReduce 是一种用于处理和生成大规模数据集的编程模型。它将数据处理分为两个主要阶段：Map 和 Reduce，从而实现对大数据的并行计算和分布式处理。MapReduce的设计目标是能够在计算机集群上高效处理TB级甚至PB级的数据集。
2.编程模型 例如大型文档集合中每个单词出现次数的问题，我们可以使用MapReduce处理，下文将默认处理该问题。
2.1Example 伪代码：
map(String key, String value):
// key: document name
// value: document contents
for each word w in value:
EmitIntermediate(w, “1”);
reduce(String key, Iterator values):
// key: a word
// values: a list of counts
int result = 0;
for each v in values:
result &#43;= ParseInt(v);
Emit(AsString(result));
map函数发出每个单词加上一个相关的出现次数计数(在这个简单的示例中只有’ 1 ‘)。reduce函数将针对特定单词发出的所有计数求和。 mapTask函数具体实现：">
  <meta itemprop="wordCount" content="755">
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Wei Haoyu">
  <meta name="twitter:description" content="点击返回🔗我的博客文章目录
目录 {:toc} paper link
1.介绍 MapReduce 是一种用于处理和生成大规模数据集的编程模型。它将数据处理分为两个主要阶段：Map 和 Reduce，从而实现对大数据的并行计算和分布式处理。MapReduce的设计目标是能够在计算机集群上高效处理TB级甚至PB级的数据集。
2.编程模型 例如大型文档集合中每个单词出现次数的问题，我们可以使用MapReduce处理，下文将默认处理该问题。
2.1Example 伪代码：
map(String key, String value):
// key: document name
// value: document contents
for each word w in value:
EmitIntermediate(w, “1”);
reduce(String key, Iterator values):
// key: a word
// values: a list of counts
int result = 0;
for each v in values:
result &#43;= ParseInt(v);
Emit(AsString(result));
map函数发出每个单词加上一个相关的出现次数计数(在这个简单的示例中只有’ 1 ‘)。reduce函数将针对特定单词发出的所有计数求和。 mapTask函数具体实现：">

	
  </head><body class="ma0 avenir bg-near-white development">

    
   
  

  <header>
    <div class="bg-black">
      <nav class="pv3 ph3 ph4-ns" role="navigation">
  <div class="flex-l center items-center justify-between">
    <a href="/" class="f3 fw2 hover-white white-90 dib no-underline">
      
        Wei Haoyu
      
    </a>
    <div class="flex-l items-center">
      

      
      <div class="ananke-socials"></div>

    </div>
  </div>
</nav>

    </div>
  </header>



    <main class="pb7" role="main">
      
  
  
  <article class="flex-l mw8 center ph3 flex-wrap justify-between">
    <header class="mt4 w-100">
      <aside class="instapaper_ignoref b helvetica tracked ttu">
          
        Posts
      </aside><div id="sharing" class="mt3 ananke-socials"></div>
<h1 class="f1 athelas mt3 mb1"></h1>
      
      
      

      
      
    </header>
    <div class="nested-copy-line-height lh-copy serif f4 nested-links mid-gray pr4-l w-two-thirds-l"><p>点击返回<a href="https://2549141519.github.io/#/toc">🔗我的博客文章目录</a></p>
<ul>
<li>目录
{:toc}</li>
</ul>
<!-- raw HTML omitted -->
<p>paper <a href="https://static.googleusercontent.com/media/research.google.com/en//archive/mapreduce-osdi04.pdf">link</a></p>
<h1 id="1介绍">1.介绍</h1>
<p>MapReduce 是一种用于处理和生成大规模数据集的编程模型。它将数据处理分为两个主要阶段：Map 和 Reduce，从而实现对大数据的并行计算和分布式处理。MapReduce的设计目标是能够在计算机集群上高效处理TB级甚至PB级的数据集。</p>
<h1 id="2编程模型">2.编程模型</h1>
<p>例如大型文档集合中每个单词出现次数的问题，我们可以使用MapReduce处理，下文将默认处理该问题。</p>
<h2 id="21example">2.1Example</h2>
<p>伪代码：</p>
<blockquote>
<p>map(String key, String value):<br>
// key: document name<br>
// value: document contents<br>
for each word w in value:<br>
EmitIntermediate(w, &ldquo;1&rdquo;);<br>
reduce(String key, Iterator values):<br>
// key: a word<br>
// values: a list of counts<br>
int result = 0;<br>
for each v in values:<br>
result += ParseInt(v);<br>
Emit(AsString(result));</p></blockquote>
<p>map函数发出每个单词加上一个相关的出现次数计数(在这个简单的示例中只有&rsquo; 1 &lsquo;)。reduce函数将针对特定单词发出的所有计数求和。
mapTask函数具体实现：</p>
<blockquote>
<p>func mapTask(mapf func(string, string) []KeyValue, file string, mapID int, nReduce int) (map[string][]KeyValue, error) {<br>
// 读取文件内容<br>
content, err := os.ReadFile(file)<br>
if err != nil {<br>
return nil, fmt.Errorf(&ldquo;cannot read file %v: %v&rdquo;, file, err)<br>
}<br>
// 调用用户提供的 map 函数生成键值对<br>
kvs := mapf(file, string(content))<br>
// 初始化中间数据<br>
intermediateData := make(map[string][]KeyValue)<br>
// 初始化中间文件和编码器<br>
intermediateFiles := make([]*os.File, nReduce)<br>
encoders := make([]*json.Encoder, nReduce)<br>
for i := 0; i &lt; nReduce; i++ {<br>
intermediateFileName := fmt.Sprintf(&ldquo;mr-%d-%d&rdquo;, mapID, i)<br>
intermediateFile, err := os.Create(intermediateFileName)<br>
if err != nil {<br>
log.Printf(&ldquo;Worker: Cannot create intermediate file %s: %v&rdquo;, intermediateFileName, err)<br>
return nil, fmt.Errorf(&ldquo;cannot create intermediate file %s: %v&rdquo;, intermediateFileName, err)<br>
}<br>
defer intermediateFile.Close()<br>
intermediateFiles[i] = intermediateFile<br>
encoders[i] = json.NewEncoder(intermediateFile)<br>
}<br>
// 对每个键值对进行哈希，根据哈希值决定写入哪个Reduce任务的中间文件<br>
for _, kv := range kvs {<br>
reduceTask := ihash(kv.Key) % nReduce<br>
if err := encoders[reduceTask].Encode(&amp;kv); err != nil {<br>
log.Printf(&ldquo;Worker: Cannot encode intermediate data for reduce task %d: %v&rdquo;, reduceTask, err)<br>
return nil, fmt.Errorf(&ldquo;cannot encode intermediate data for reduce task %d: %v&rdquo;, reduceTask, err)<br>
}<br>
intermediateData[fmt.Sprintf(&ldquo;mr-%d-%d&rdquo;, mapID, reduceTask)] = append(intermediateData[fmt.Sprintf(&ldquo;mr-%d-%d&rdquo;, mapID, reduceTask)], kv)<br>
}<br>
return intermediateData, nil<br>
}</p></blockquote>
<p>reduceTask函数具体实现：</p>
<blockquote>
<p>func reduceTask(reducef func(string, []string) string, reduceID int, nMap int) error {<br>
intermediate := []KeyValue{}<br>
// 读取所有中间文件并解析键值对<br>
for i := 0; i &lt; nMap; i++ {<br>
intermediateFileName := fmt.Sprintf(&ldquo;mr-%d-%d&rdquo;, i, reduceID)<br>
file, err := os.Open(intermediateFileName)<br>
if err != nil {<br>
return fmt.Errorf(&ldquo;cannot open intermediate file %s: %v&rdquo;, intermediateFileName, err)<br>
}<br>
dec := json.NewDecoder(file)<br>
for {<br>
var kv KeyValue<br>
if err := dec.Decode(&amp;kv); err != nil {<br>
if err.Error() == &ldquo;EOF&rdquo; {<br>
break<br>
}<br>
return fmt.Errorf(&ldquo;error decoding intermediate file %s: %v&rdquo;, intermediateFileName, err)<br>
}<br>
intermediate = append(intermediate, kv)<br>
}<br>
defer file.Close() // 确保在每次读取文件后关闭文件<br>
}<br>
// 按键排序<br>
sort.Slice(intermediate, func(i, j int) bool {<br>
return intermediate[i].Key &lt; intermediate[j].Key<br>
})<br>
// 创建输出文件<br>
outputFileName := fmt.Sprintf(&ldquo;mr-out-%d&rdquo;, reduceID)<br>
ofile, err := os.Create(outputFileName)<br>
if err != nil {<br>
return fmt.Errorf(&ldquo;cannot create output file %s: %v&rdquo;, outputFileName, err)<br>
}<br>
defer ofile.Close()<br>
// Reduce阶段，按键合并相同的键，并调用用户定义的Reduce函数<br>
i := 0<br>
for i &lt; len(intermediate) {<br>
j := i + 1<br>
// 找出所有具有相同键的值<br>
for j &lt; len(intermediate) &amp;&amp; intermediate[j].Key == intermediate[i].Key {<br>
j++<br>
}<br>
values := []string{}<br>
for k := i; k &lt; j; k++ {<br>
values = append(values, intermediate[k].Value)<br>
}<br>
// 调用用户提供的Reduce函数处理值<br>
output := reducef(intermediate[i].Key, values)<br>
// 按指定格式输出结果<br>
fmt.Fprintf(ofile, &ldquo;%v %v\n&rdquo;, intermediate[i].Key, output)<br>
i = j<br>
}<br>
return nil<br>
}</p></blockquote>
<h2 id="22执行概述">2.2执行概述</h2>
<p><img src="../blogImg/%E6%89%A7%E8%A1%8C%E6%A6%82%E8%BF%B0.PNG" alt="Alt text"></p>
<p>Map阶段：在Map阶段，输入数据被分成多个小片段（称为分片，split），每个分片都作为一个键值对（key-value pair）传递给Map函数。Map函数对输入的键值对进行处理，然后生成一组中间的键值对。这些中间键值对通常会按照键进行分组，以便后续的Reduce阶段进行处理。
例如，如果我们想统计一个文本文件中每个单词出现的次数，Map函数的输入是文件中的每一行（作为value），每一行被分割成单词，然后Map函数输出一个单词和计数值（初始为1）的键值对。</p>
<p>有一个特殊的master和多个由master分配的worker。
有M个map任务和R个reduce任务要分配。master选择空闲的worker，并为每个worker分配一个map任务或reduce任务。</p>
<p>一个被分配Map任务的worker需要从切片中读取内容，从中解析出key/value对后传入用户定义的map方法，map方法产生的中间key/value对放在内存缓冲区中。</p>
<p>这些key/value对周期性的写入磁盘，它们在磁盘的位置被传递给master，master将这些数据分配给执行reduce任务的worker。</p>
<p>当reduce worker读取了所有中间数据后，它按中间键对数据进行排序，以便将所有出现的相同键分组在一起。</p>
<p>reduce worker遍历所有的中间数据，将每个唯一的中间数据传给用户定义的reduce函数。</p>
<h2 id="23master-data-structures">2.3Master Data Structures</h2>
<p>Master结构体的定义举例：</p>
<blockquote>
<p>type Master struct {<br>
files            []string                      // 输入文件列表<br>
nReduce          int                           // reduce 任务数量<br>
mapTasks         int                           // map 任务数量<br>
reduceTasks      int                           // reduce 任务数量<br>
taskStatus       map[int]string                // 任务状态<br>
taskMutex        sync.Mutex                    // 互斥锁<br>
done             bool                          // 任务是否完成<br>
intermediateData map[int]map[string][]KeyValue // 中间数据<br>
taskTimeout      map[int]time.Time             // 任务超时时间<br>
timeout          time.Duration                 // 任务超时时间间隔<br>
}</p></blockquote>
<h2 id="24分配任务">2.4分配任务</h2>
<p>下面是分配任务函数（GetTask）例子：</p>
<blockquote>
<p>func (m *Master) GetTask(args *TaskRequest, reply *TaskReply) error {<br>
m.taskMutex.Lock()<br>
defer m.taskMutex.Unlock()<br>
// 检查是否所有任务都已完成<br>
if m.done {<br>
reply.TaskType = &quot;&quot; // 显式设置为空的任务类型以表示没有更多任务<br>
return nil<br>
}<br>
now := time.Now()<br>
taskAssigned := false<br>
// 首先检查是否有所有 Map 任务完成<br>
allMapCompleted := true<br>
for i := 0; i &lt; m.mapTasks; i++ {<br>
status, ok := m.taskStatus[i]<br>
if !ok || status != &ldquo;completed&rdquo; {<br>
allMapCompleted = false<br>
break<br>
}<br>
}<br>
if !allMapCompleted {<br>
// 分配 Map 任务<br>
for i := 0; i &lt; m.mapTasks; i++ {<br>
status, ok := m.taskStatus[i]<br>
if (!ok || status == &ldquo;pending&rdquo;) || (status == &ldquo;in-progress&rdquo; &amp;&amp; now.Sub(m.taskTimeout[i]) &gt; m.timeout) {<br>
reply.TaskType = string(Map)<br>
reply.TaskID = i<br>
reply.NMap = len(m.files)<br>
reply.File = m.files[i]<br>
reply.NReduce = m.nReduce<br>
reply.Data = make(map[string][]KeyValue)<br>
m.taskStatus[i] = &ldquo;in-progress&rdquo;<br>
m.taskTimeout[i] = now<br>
taskAssigned = true<br>
break<br>
}<br>
}<br>
} else {<br>
// 如果所有 Map 任务完成，分配 Reduce 任务<br>
for i := 0; i &lt; m.reduceTasks; i++ {<br>
status, ok := m.taskStatus[i+m.mapTasks]<br>
if (!ok || status == &ldquo;pending&rdquo;) || (status == &ldquo;in-progress&rdquo; &amp;&amp; now.Sub(m.taskTimeout[i+m.mapTasks]) &gt; m.timeout) {<br>
reply.TaskType = string(Reduce)<br>
reply.TaskID = i + m.mapTasks<br>
reply.NMap = len(m.files)<br>
reply.ReduceID = i<br>
reply.NReduce = m.nReduce<br>
reply.Data = make(map[string][]KeyValue)<br>
m.taskStatus[i+m.mapTasks] = &ldquo;in-progress&rdquo;<br>
m.taskTimeout[i+m.mapTasks] = now<br>
taskAssigned = true<br>
break<br>
}<br>
}<br>
}<br>
if taskAssigned {<br>
return nil<br>
}<br>
// 如果没有可分配的任务，检查所有任务是否完成<br>
allCompleted := true<br>
for _, status := range m.taskStatus {<br>
if status != &ldquo;completed&rdquo; {<br>
allCompleted = false<br>
break<br>
}<br>
}<br>
if allCompleted {<br>
m.done = true<br>
reply.TaskType = &quot;&quot; // 没有更多任务时显式设置为空<br>
}<br>
return nil<br>
}</p></blockquote>
<h1 id="3高可用">3.高可用</h1>
<h2 id="31worker宕机">3.1worker宕机</h2>
<p>master定期ping每个worker。如果在一定时间内没有收到来自worker的响应，则master将该worker标记为失败。工作线程完成的任何maptask都被重置回其初始空闲状态，因此可以在其他工作线程上调度。在失败的worker上正在进行的任何map任务或reducetask也被重置为空闲，并有资格重新调度。
完成的map任务在发生故障时重新执行，因为它们的输出存储在故障机器的本地磁盘上，因此无法访问。
完成的reduce任务不需要重新执行，因为它们的输出存储在全局文件系统中。当map任务首先由worker A执行，然后由worker B执行(因为A失败)时，master会通知执行reduce任务的worker重执行。任何尚未从worker A读取数据的reduce任务都将从worker B读取数据。</p>
<h2 id="32master宕机">3.2master宕机</h2>
<p>master定期将它维护的关键数据结构（如任务状态、资源分配信息等）写入检查点（checkpoint）。如果master宕机了，系统可以从最后一次检查点的状态恢复，而不需要从头开始整个计算。
如果master的任务失败（即master宕机或崩溃），可以从最后一次检查点的状态重新启动一个新的master副本。这个新的master将从保存的检查点状态中恢复，继续进行MapReduce计算。</p>
<ul class="pa0">
  
</ul>
<div class="mt6 instapaper_ignoref">
      
      
      </div>
    </div>

    <aside class="w-30-l mt6-l">




</aside>

  </article>

    </main>
    <footer class="bg-black bottom-0 w-100 pa3" role="contentinfo">
  <div class="flex justify-between">
  <a class="f4 fw4 hover-white white-70 dn dib-ns pv2 ph3 no-underline" href="http://localhost:1313/" >
    &copy;  Wei Haoyu 2025 
  </a>
    <div><div class="ananke-socials"></div>
</div>
  </div>
</footer>

  </body>
</html>
